# é‡æ–°æ‰§è¡Œä»£ç ä¿å­˜é€»è¾‘ï¼Œå› ä¸ºå‰é¢çš„çŠ¶æ€å·²ç»é‡ç½®äº†
import os

# åˆ›å»ºæœ€ç»ˆè¾“å‡ºçš„ app.py æ–‡ä»¶ç»“æ„ï¼ˆå·²é›†æˆç”¨æˆ·éœ€æ±‚ï¼‰
app_py_code = """
import streamlit as st
import pandas as pd
import datetime
import io
import time
import docx
import fitz  # PyMuPDFï¼Œç”¨äºPDFè§£æ
import re

# ===== å…¬å…±å‡½æ•° =====

# è®¡ç®—å‰©ä½™å¤©æ•°
def calculate_days_left(cutoff_date):
    return (cutoff_date - datetime.datetime.now().date()).days

# ä¸­è‹±æ–‡ç¿»è¯‘ï¼ˆç®€å•è§„åˆ™æ˜ å°„ï¼‰
translation_dict = {
    "title": "æ ‡é¢˜",
    "abstract": "æ‘˜è¦",
    "keywords": "å…³é”®è¯"
}

def translate_term(term):
    return translation_dict.get(term.lower(), term)

# è¯»å–PDFæ–‡æœ¬
def extract_text_from_pdf(file):
    text = ""
    with fitz.open(stream=file.read(), filetype="pdf") as doc:
        for page in doc:
            text += page.get_text()
    return text

# è¯»å–DOCXæ–‡æœ¬
def extract_text_from_docx(file):
    doc = docx.Document(file)
    return "\\n".join([para.text for para in doc.paragraphs])

# æå–æ ‡é¢˜ã€æ‘˜è¦ã€å…³é”®è¯
def extract_paper_fields(text):
    fields = {"title": "", "abstract": "", "keywords": ""}
    lines = text.split("\\n")
    for line in lines:
        line_lower = line.lower().strip()
        if line_lower.startswith("title:") or line_lower.startswith("æ ‡é¢˜ï¼š"):
            fields["title"] = line.split(":", 1)[-1].strip()
        elif line_lower.startswith("abstract:") or line_lower.startswith("æ‘˜è¦ï¼š"):
            fields["abstract"] = line.split(":", 1)[-1].strip()
        elif line_lower.startswith("keywords:") or line_lower.startswith("å…³é”®è¯ï¼š"):
            fields["keywords"] = line.split(":", 1)[-1].strip()
    return fields

# æ¨¡æ‹Ÿç¿»è¯‘
def mock_translate(text):
    return "ï¼ˆç¿»è¯‘ï¼‰" + text if text else ""

# åˆ†æè®ºæ–‡å†…å®¹
def analyze_paper_subject(paper_text):
    st.subheader("ğŸ“˜ è®ºæ–‡åŸºæœ¬ä¿¡æ¯æå–ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰")
    fields = extract_paper_fields(paper_text)
    for key in ["title", "abstract", "keywords"]:
        en = fields[key]
        zh = mock_translate(en)
        st.write(f"**{translate_term(key)}:** {en}")
        st.write(f"**{translate_term(key)}ï¼ˆä¸­æ–‡ï¼‰:** {zh}")
    
    st.subheader("ğŸ“Š è®ºæ–‡å­¦ç§‘æ–¹å‘åˆ†æï¼š")
    subjects = {
        "ç”µåŠ›ç³»ç»Ÿ": 40,
        "æ§åˆ¶ç†è®º": 35,
        "è®¡ç®—æœºç§‘å­¦": 25
    }
    for subject, percent in subjects.items():
        st.write(f"{subject}: {percent}%")
    return subjects

# ä¸Šä¼ æ–‡ä»¶å‡½æ•°
def upload_conference_file():
    return st.file_uploader("ğŸ“ ä¸Šä¼ ä¼šè®®æ–‡ä»¶", type=["xlsx", "xls"], key="conference")

def upload_paper_file():
    return st.file_uploader("ğŸ“„ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶", type=["pdf", "docx"], key="paper")

# åŒ¹é…å‡½æ•°
def perform_matching(conference_file, paper_subjects):
    try:
        conference_data = pd.read_excel(conference_file)
        st.success("âœ… ä¼šè®®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        matching_conferences = []
        for index, row in conference_data.iterrows():
            if 'Symposium' not in row['ä¼šè®®å']:
                conference_subjects = row['ä¼šè®®ä¸»é¢˜æ–¹å‘'].split(',')
                score = sum(paper_subjects.get(s.strip(), 0) for s in conference_subjects)
                if score > 0:
                    matching_conferences.append({
                        "ä¼šè®®ç³»åˆ—åä¸ä¼šè®®å": f"{row['ä¼šè®®ç³»åˆ—å']} - {row['ä¼šè®®å']}",
                        "å®˜ç½‘é“¾æ¥": row['å®˜ç½‘é“¾æ¥'],
                        "åŠ¨æ€å‡ºç‰ˆæ ‡è®°": row['åŠ¨æ€å‡ºç‰ˆæ ‡è®°'],
                        "æˆªç¨¿æ—¶é—´": row['æˆªç¨¿æ—¶é—´'],
                        "å‰©ä½™å¤©æ•°": calculate_days_left(row['æˆªç¨¿æ—¶é—´']),
                        "åŒ¹é…è¯´æ˜": f"ä¸æ–¹å‘[{row['ä¼šè®®ä¸»é¢˜æ–¹å‘']}]æœ‰äº¤é›†"
                    })
        if matching_conferences:
            st.subheader("ğŸ¯ æ¨èä¼šè®®åˆ—è¡¨ï¼š")
            for conf in matching_conferences:
                st.write(f"**ä¼šè®®ï¼š{conf['ä¼šè®®ç³»åˆ—åä¸ä¼šè®®å']}**")
                st.markdown(f"[ç‚¹å‡»è®¿é—®å®˜ç½‘é“¾æ¥]({conf['å®˜ç½‘é“¾æ¥']})", unsafe_allow_html=True)
                st.write(f"åŠ¨æ€å‡ºç‰ˆ: {conf['åŠ¨æ€å‡ºç‰ˆæ ‡è®°']}")
                st.write(f"æˆªç¨¿æ—¶é—´: {conf['æˆªç¨¿æ—¶é—´']}ï¼ˆè¿˜å‰© {conf['å‰©ä½™å¤©æ•°']} å¤©ï¼‰")
                st.write(f"åŒ¹é…è¯´æ˜: {conf['åŒ¹é…è¯´æ˜']}")
        else:
            st.warning("âš ï¸ æœªå‘ç°åŒ¹é…ä¼šè®®ï¼Œå»ºè®®å…³æ³¨ç”µåŠ›ç³»ç»Ÿã€æ§åˆ¶ç†è®ºç­‰æ–¹å‘çš„ä¼šè®®")
    except Exception as e:
        st.error(f"âŒ åŠ è½½ä¼šè®®æ–‡ä»¶å‡ºé”™: {e}")

# ä¸»ç¨‹åºå…¥å£
def main():
    st.set_page_config(layout="wide")
    st.title("ğŸ“‘ è®ºæ–‡ä¸ä¼šè®®åŒ¹é…ç³»ç»Ÿ")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("### ğŸ“¥ ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
        conference_file = upload_conference_file()

    with col2:
        st.markdown("### ğŸ“¥ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
        paper_file = upload_paper_file()

    if paper_file:
        try:
            if paper_file.name.endswith(".pdf"):
                paper_text = extract_text_from_pdf(paper_file)
            elif paper_file.name.endswith(".docx"):
                paper_text = extract_text_from_docx(paper_file)
            else:
                st.error("ä¸æ”¯æŒçš„è®ºæ–‡æ–‡ä»¶æ ¼å¼")
                return

            # è®ºæ–‡åˆ†æ
            paper_subjects = analyze_paper_subject(paper_text)

            # åŒ¹é…ä¼šè®®ï¼ˆå¦‚å·²ä¸Šä¼ ï¼‰
            if conference_file:
                perform_matching(conference_file, paper_subjects)
            else:
                st.info("ğŸ“Œ è‹¥è¦æŸ¥çœ‹åŒ¹é…ä¼šè®®ï¼Œè¯·ä¸Šä¼ ä¼šè®®æ–‡ä»¶")

        except Exception as e:
            st.error(f"è®ºæ–‡æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
    else:
        st.info("è¯·ä¸Šä¼ è®ºæ–‡æ–‡ä»¶è¿›è¡Œåˆ†æ")

if __name__ == "__main__":
    main()
"""

# ä¿å­˜ä»£ç ä¸º app.py
output_path = "/mnt/data/app.py"
with open(output_path, "w", encoding="utf-8") as f:
    f.write(app_py_code)

output_path
