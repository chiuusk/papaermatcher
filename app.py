import streamlit as st
import pandas as pd
import datetime
import time
import re
import fitz  # PyMuPDF
import docx
from deep_translator import GoogleTranslator

# ------------------- å·¥å…·å‡½æ•° -------------------

def calculate_days_left(cutoff_date):
    return (cutoff_date - datetime.datetime.now().date()).days

def extract_text_from_pdf(pdf_file):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    text = ""
    for page in doc:
        text += page.get_text()
    return text

def extract_text_from_docx(docx_file):
    doc = docx.Document(docx_file)
    return "\n".join([para.text for para in doc.paragraphs])

def extract_title(text):
    lines = text.strip().split('\n')
    for line in lines:
        if 5 < len(line.strip()) < 200:
            return line.strip()
    return "æœªè¯†åˆ«åˆ°æ ‡é¢˜"

def extract_keywords(text):
    patterns = [
        r"(å…³é”®è¯|Key words|Keywords)[:ï¼š]?\s*(.+)",
    ]
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(2).strip()
    return "æœªè¯†åˆ«åˆ°å…³é”®è¯"

def translate_to_english(text):
    try:
        return GoogleTranslator(source='auto', target='en').translate(text)
    except:
        return "(ç¿»è¯‘å¤±è´¥)"

def analyze_paper_subject(text):
    return {
        "ç”µåŠ›ç³»ç»Ÿ": 40,
        "æ§åˆ¶ç†è®º": 35,
        "è®¡ç®—æœºç§‘å­¦": 25
    }

# ------------------- æ–‡ä»¶ä¸Šä¼  -------------------

def upload_conference_file():
    return st.file_uploader("ä¸Šä¼ ä¼šè®®æ–‡ä»¶", type=["xlsx"], key="conference_file")

def upload_paper_file():
    return st.file_uploader("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶", type=["pdf", "docx"], key="paper_file")

# ------------------- åŒ¹é…é€»è¾‘ -------------------

def perform_matching(conference_file, paper_subjects):
    if conference_file is None:
        st.warning("æœªä¸Šä¼ ä¼šè®®æ–‡ä»¶ï¼Œæ— æ³•è¿›è¡Œä¼šè®®åŒ¹é…")
        return

    try:
        df = pd.read_excel(conference_file)
        st.success("ä¼šè®®æ–‡ä»¶åŠ è½½æˆåŠŸ")

        matching_confs = []
        for _, row in df.iterrows():
            conf_subjects = row['ä¼šè®®ä¸»é¢˜æ–¹å‘'].split(',') if pd.notna(row['ä¼šè®®ä¸»é¢˜æ–¹å‘']) else []
            match_score = sum(paper_subjects.get(s.strip(), 0) for s in conf_subjects)
            if match_score > 0:
                matching_confs.append({
                    "ä¼šè®®": f"{row['ä¼šè®®ç³»åˆ—å']} - {row['ä¼šè®®å']}",
                    "é“¾æ¥": row['å®˜ç½‘é“¾æ¥'],
                    "å‡ºç‰ˆæ ‡è®°": row['åŠ¨æ€å‡ºç‰ˆæ ‡è®°'],
                    "æˆªç¨¿": row['æˆªç¨¿æ—¶é—´'],
                    "å‰©ä½™å¤©æ•°": calculate_days_left(row['æˆªç¨¿æ—¶é—´']),
                    "åŒ¹é…åˆ†æ": f"è®ºæ–‡æ–¹å‘ä¸ {row['ä¼šè®®ä¸»é¢˜æ–¹å‘']} æœ‰å…³"
                })

        if matching_confs:
            st.subheader("ğŸ¯ æ¨èä¼šè®®ï¼š")
            for c in matching_confs:
                st.markdown(f"**{c['ä¼šè®®']}**")
                st.markdown(f"- å®˜ç½‘é“¾æ¥: [{c['é“¾æ¥']}]({c['é“¾æ¥']})")
                st.markdown(f"- åŠ¨æ€å‡ºç‰ˆæ ‡è®°: {c['å‡ºç‰ˆæ ‡è®°']}")
                st.markdown(f"- æˆªç¨¿æ—¶é—´: {c['æˆªç¨¿']} (å‰©ä½™ {c['å‰©ä½™å¤©æ•°']} å¤©)")
                st.markdown(f"- åŒ¹é…åˆ†æ: {c['åŒ¹é…åˆ†æ']}")
        else:
            st.info("âš ï¸ æœªåŒ¹é…åˆ°åˆé€‚çš„ä¼šè®®ï¼Œè¯·æŸ¥çœ‹å­¦ç§‘æ–¹å‘å»ºè®®")
    except Exception as e:
        st.error(f"ä¼šè®®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")

# ------------------- ä¸»å‡½æ•° -------------------

def main():
    st.set_page_config(layout="wide")
    st.title("ğŸ“„ è®ºæ–‡ä¸ä¼šè®®åŒ¹é…ç³»ç»Ÿ")

    col1, col2 = st.columns(2)

    with col1:
        st.header("ğŸ“ ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
        conference_file = upload_conference_file()

    with col2:
        st.header("ğŸ“„ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
        paper_file = upload_paper_file()

        if paper_file:
            st.success("è®ºæ–‡æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨è§£æ...")

            if paper_file.name.endswith(".pdf"):
                text = extract_text_from_pdf(paper_file)
            elif paper_file.name.endswith(".docx"):
                text = extract_text_from_docx(paper_file)
            else:
                st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                return

            title_cn = extract_title(text)
            keywords_cn = extract_keywords(text)
            title_en = translate_to_english(title_cn)
            keywords_en = translate_to_english(keywords_cn)

            st.subheader("ğŸ“Œ è®ºæ–‡ä¿¡æ¯æå–ä¸ç¿»è¯‘")
            st.markdown(f"**é¢˜ç›®ï¼ˆä¸­æ–‡ï¼‰ï¼š** {title_cn}")
            st.markdown(f"**Title (English):** {title_en}")
            st.markdown(f"**å…³é”®è¯ï¼ˆä¸­æ–‡ï¼‰ï¼š** {keywords_cn}")
            st.markdown(f"**Keywords (English):** {keywords_en}")

            subjects = analyze_paper_subject(text)
            st.subheader("ğŸ“š å­¦ç§‘æ–¹å‘åˆ†æ")
            for subject, weight in subjects.items():
                st.write(f"{subject}: {weight}%")

            perform_matching(conference_file, subjects)
        else:
            st.info("è¯·ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ä»¥è¿›è¡Œæå–åˆ†æ")

if __name__ == "__main__":
    main()
