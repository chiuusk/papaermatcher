import streamlit as st
import pandas as pd
import datetime
import os
import re
import time
from io import StringIO
from PyPDF2 import PdfReader
import docx

st.set_page_config(page_title="è®ºæ–‡ä¼šè®®åŒ¹é…æ¨èç³»ç»Ÿ", layout="wide")

def extract_text_from_pdf(uploaded_file):
    try:
        reader = PdfReader(uploaded_file)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
        return text
    except:
        return ""

def extract_text_from_docx(uploaded_file):
    try:
        doc = docx.Document(uploaded_file)
        return "\n".join([p.text for p in doc.paragraphs])
    except:
        return ""

def extract_title_abstract_keywords(text):
    title = ""
    abstract = ""
    keywords = ""
    lines = text.split("\n")
    for i, line in enumerate(lines):
        line = line.strip()
        if not title and 5 < len(line) < 200:
            title = line
        if 'abstract' in line.lower():
            abstract = lines[i+1] if i+1 < len(lines) else ""
        if 'keywords' in line.lower():
            keywords = lines[i+1] if i+1 < len(lines) else ""
    return title.strip(), abstract.strip(), keywords.strip()

def analyze_disciplines(title, abstract, keywords):
    combined = f"{title} {abstract} {keywords}".lower()
    disciplines = {
        "è®¡ç®—æœºç§‘å­¦": ["algorithm", "neural", "network", "learning", "data", "vision", "nlp", "cnn", "transformer"],
        "ç”µå­å·¥ç¨‹": ["circuit", "voltage", "rectifier", "power", "signal", "pwm", "electronics", "amplifier"],
        "æ§åˆ¶ç§‘å­¦": ["control", "pi", "fuzzy", "reinforcement", "autonomous", "controller", "pid"],
        "é€šä¿¡å·¥ç¨‹": ["communication", "transmission", "modulation", "bandwidth", "antenna", "channel"],
        "äººå·¥æ™ºèƒ½": ["deep learning", "reinforcement learning", "machine learning", "ai", "agent", "training"],
        "æœºæ¢°å·¥ç¨‹": ["robot", "mechanical", "structure", "dynamics", "kinematics"],
        "åŒ»å­¦": ["patient", "disease", "clinical", "hospital", "symptom", "therapy"],
        "å¿ƒç†å­¦": ["behavior", "emotion", "psychology", "mental"],
        "ç¤¾ä¼šå­¦": ["society", "social", "survey", "education", "policy"]
    }
    result = []
    for d, kws in disciplines.items():
        score = sum(1 for kw in kws if kw in combined)
        if score > 0:
            result.append((d, score))
    total = sum(s for _, s in result)
    if total == 0:
        return []
    result_sorted = sorted(result, key=lambda x: -x[1])
    return [(d, round(s / total * 100, 2)) for d, s in result_sorted[:5]]

def calculate_days_left(cutoff_date):
    try:
        return (cutoff_date - datetime.datetime.now().date()).days
    except:
        return "æœªçŸ¥"

def keyword_matches(paper_text, conference_keywords):
    paper_text = paper_text.lower()
    matches = []
    for kw in str(conference_keywords).split(","):
        if kw.strip().lower() in paper_text:
            matches.append(kw.strip())
    return matches

def section_title(title):
    st.markdown(f"### {title}")

def subsection_title(sub):
    st.markdown(f"**{sub}**")

def main():
    st.title("ğŸ“„ è®ºæ–‡ä¼šè®®åŒ¹é…æ¨èç³»ç»Ÿ")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("#### ä¸Šä¼ ä¼šè®®æ–‡ä»¶ï¼ˆExcelï¼‰")
        conf_file = st.file_uploader("ğŸ“ ä¸Šä¼ ä¼šè®® Excel æ–‡ä»¶", type=["xlsx"], key="conf")

    with col2:
        st.markdown("#### ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ï¼ˆPDF / DOCXï¼‰")
        paper_file = st.file_uploader("ğŸ“„ ä¸Šä¼ è®ºæ–‡ PDF æˆ– Word æ–‡ä»¶", type=["pdf", "docx"], key="paper")

    paper_text = ""
    title, abstract, keywords = "", "", ""
    disciplines = []

    if paper_file:
        with st.spinner("ğŸ” æ­£åœ¨è¯»å–è®ºæ–‡å†…å®¹å¹¶åˆ†æå­¦ç§‘æ–¹å‘..."):
            if paper_file.type == "application/pdf":
                paper_text = extract_text_from_pdf(paper_file)
            elif paper_file.type in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document"]:
                paper_text = extract_text_from_docx(paper_file)

            title, abstract, keywords = extract_title_abstract_keywords(paper_text)
            disciplines = analyze_disciplines(title, abstract, keywords)

            section_title("ğŸ“˜ è®ºæ–‡å­¦ç§‘æ–¹å‘åˆ†æ")
            st.markdown(f"**æ ‡é¢˜ï¼š** {title}")
            st.markdown(f"**æ‘˜è¦ï¼š** {abstract}")
            st.markdown(f"**å…³é”®è¯ï¼š** {keywords}")
            if disciplines:
                for d, p in disciplines:
                    st.markdown(f"- **{d}**ï¼ˆå æ¯”ï¼š{p}%ï¼‰")
            else:
                st.warning("æœªèƒ½è¯†åˆ«æ˜ç¡®çš„å­¦ç§‘æ–¹å‘")

    if paper_file and conf_file:
        section_title("ğŸ“Œ åŒ¹é…æ¨èç»“æœ")
        with st.spinner("ğŸ¤– æ­£åœ¨åŒ¹é…æ¨èä¼šè®®..."):
            conf_df = pd.read_excel(conf_file)

            required_fields = {"ä¼šè®®å", "ä¼šè®®ç³»åˆ—å", "ä¼šè®®ä¸»é¢˜æ–¹å‘", "ç»†åˆ†å…³é”®è¯", "æˆªç¨¿æ—¶é—´", "å®˜ç½‘é“¾æ¥", "åŠ¨æ€å‡ºç‰ˆæ ‡è®°"}
            if not required_fields.issubset(conf_df.columns):
                st.error(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µï¼š{required_fields - set(conf_df.columns)}")
                return

            matches = []
            for _, row in conf_df.iterrows():
                combined_keywords = f"{row['ä¼šè®®ä¸»é¢˜æ–¹å‘']} {row['ç»†åˆ†å…³é”®è¯']}"
                matched_keywords = keyword_matches(paper_text, combined_keywords)
                score = len(matched_keywords)
                if score > 0:
                    matches.append({
                        "ä¼šè®®æ ‡é¢˜": f"{row['ä¼šè®®ç³»åˆ—å']} - {row['ä¼šè®®å']}",
                        "å®˜ç½‘é“¾æ¥": row["å®˜ç½‘é“¾æ¥"],
                        "åŠ¨æ€å‡ºç‰ˆæ ‡è®°": row["åŠ¨æ€å‡ºç‰ˆæ ‡è®°"],
                        "æˆªç¨¿æ—¶é—´": row["æˆªç¨¿æ—¶é—´"],
                        "åŒ¹é…å…³é”®è¯": ", ".join(matched_keywords),
                        "åŒ¹é…ç¨‹åº¦": score
                    })

            if matches:
                matches = sorted(matches, key=lambda x: -x["åŒ¹é…ç¨‹åº¦"])
                for m in matches[:3]:
                    subsection_title(m["ä¼šè®®æ ‡é¢˜"])
                    st.markdown(f"- **å®˜ç½‘é“¾æ¥ï¼š** [{m['å®˜ç½‘é“¾æ¥']}]({m['å®˜ç½‘é“¾æ¥']})")
                    st.markdown(f"- **åŠ¨æ€å‡ºç‰ˆæ ‡è®°ï¼š** {m['åŠ¨æ€å‡ºç‰ˆæ ‡è®°']}")
                    st.markdown(f"- **æˆªç¨¿æ—¶é—´ï¼š** {m['æˆªç¨¿æ—¶é—´']}")
                    st.markdown(f"- **åŒ¹é…å…³é”®è¯ï¼š** {m['åŒ¹é…å…³é”®è¯']}")
            else:
                st.info("âš ï¸ æš‚æ— å®Œå…¨åŒ¹é…çš„ä¼šè®®ï¼Œä»¥ä¸‹æ˜¯åŸºäºå­¦ç§‘çš„æ¨¡ç³Šæ¨èï¼š")
                fuzzy_matches = conf_df.sample(3)
                for _, row in fuzzy_matches.iterrows():
                    subsection_title(f"{row['ä¼šè®®ç³»åˆ—å']} - {row['ä¼šè®®å']}")
                    st.markdown(f"- **å®˜ç½‘é“¾æ¥ï¼š** [{row['å®˜ç½‘é“¾æ¥']}]({row['å®˜ç½‘é“¾æ¥']})")
                    st.markdown(f"- **åŠ¨æ€å‡ºç‰ˆæ ‡è®°ï¼š** {row['åŠ¨æ€å‡ºç‰ˆæ ‡è®°']}")
                    st.markdown(f"- **æˆªç¨¿æ—¶é—´ï¼š** {row['æˆªç¨¿æ—¶é—´']}")
                    if disciplines:
                        st.markdown(f"- **åŒ¹é…è¯´æ˜ï¼š** è¯¥ä¼šè®®ä¸»é¢˜ä¸è®ºæ–‡å­¦ç§‘æ–¹å‘ **{disciplines[0][0]}** éƒ¨åˆ†ç›¸å…³")

if __name__ == "__main__":
    main()
