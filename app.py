import streamlit as st
import pandas as pd
import datetime
import os
import tempfile

st.set_page_config(layout="wide")

# -------------------- è®ºæ–‡å­¦ç§‘æ–¹å‘åˆ†æå‡½æ•° --------------------
def analyze_paper_subject(title, abstract, keywords):
    subject_keywords = {
        "ç”µåŠ›": ["ç”µæµ", "ç”µå‹", "æ§åˆ¶ç­–ç•¥", "é€†å˜å™¨", "PWM", "æ•´æµ"],
        "è®¡ç®—æœº": ["æ·±åº¦å­¦ä¹ ", "å¼ºåŒ–å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "å·ç§¯", "æ¨¡å‹", "æ•°æ®"],
        "è‡ªåŠ¨åŒ–": ["æ§åˆ¶ç³»ç»Ÿ", "PI æ§åˆ¶", "åé¦ˆ", "ä»¿çœŸ"],
        "æœºæ¢°": ["æœºå™¨äºº", "ä¼ºæœ", "é©±åŠ¨", "ä¼ æ„Ÿ"],
        "åŒ»å­¦": ["ä¸´åºŠ", "ç—…ç†", "ç”Ÿç‰©", "åŒ»å­¦å›¾åƒ"],
    }
    combined_text = f"{title} {abstract} {keywords}".lower()
    result = []
    for subject, keys in subject_keywords.items():
        count = sum(1 for k in keys if k.lower() in combined_text)
        if count > 0:
            result.append((subject, round(100 * count / len(keys), 1)))

    if not result:
        return "âŒ æœªèƒ½è¯†åˆ«æ˜ç¡®çš„å­¦ç§‘æ–¹å‘", [], "æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…å…³é”®è¯ï¼Œå¯èƒ½æ ‡é¢˜æˆ–æ‘˜è¦ä¸å¸¸è§å­¦ç§‘æœ¯è¯­å·®å¼‚è¾ƒå¤§ã€‚"

    sorted_result = sorted(result, key=lambda x: -x[1])
    explanation = "\n".join([f"- **{s}**ï¼šåŒ¹é…åº¦ {p}%ï¼ˆå› åŒ…å«å…³é”®è¯ï¼‰" for s, p in sorted_result])
    return "âœ… å­¦ç§‘æ–¹å‘è¯†åˆ«ç»“æœï¼š", sorted_result, explanation


# -------------------- å±•ç¤ºä¼šè®®åŒ¹é…ç»“æœ --------------------
def match_paper_to_conference(paper_keywords, conf_df):
    matches = []
    for _, row in conf_df.iterrows():
        if pd.isna(row.get("ä¼šè®®å")) or "symposium" not in str(row["ä¼šè®®å"]).lower():
            continue
        conf_topic = str(row.get("ä¸»é¢˜æ–¹å‘", "")).lower()
        match_score = sum(1 for kw in paper_keywords if kw.lower() in conf_topic)
        if match_score > 0:
            matches.append((row, match_score))

    if not matches:
        return None

    sorted_matches = sorted(matches, key=lambda x: -x[1])
    return [row for row, _ in sorted_matches[:3]]


# -------------------- è§£æä¸Šä¼ è®ºæ–‡æ–‡ä»¶å†…å®¹ --------------------
def extract_paper_content(file):
    if file.type == "application/pdf":
        import fitz
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = "\n".join(page.get_text() for page in doc)
    elif file.type in ["application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                       "application/msword"]:
        from docx import Document
        temp = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
        temp.write(file.read())
        temp.close()
        doc = Document(temp.name)
        text = "\n".join(p.text for p in doc.paragraphs)
        os.unlink(temp.name)
    else:
        return "", "", ""

    # ç®€åŒ–ç¤ºä¾‹æå–é€»è¾‘
    lines = text.strip().splitlines()
    title = lines[0] if lines else ""
    abstract = next((l for l in lines if "abstract" in l.lower()), "")
    keywords_line = next((l for l in lines if "keywords" in l.lower()), "")
    keywords = keywords_line.split(":")[-1] if ":" in keywords_line else keywords_line

    return title.strip(), abstract.strip(), keywords.strip()


# -------------------- ä¸»é€»è¾‘ --------------------
def main():
    st.title("ğŸ“„ è®ºæ–‡ä¼šè®®åŒ¹é…ä¸å­¦ç§‘æ–¹å‘åˆ†æå·¥å…·")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.subheader("ğŸ“¥ ä¸Šä¼ ä¼šè®®æ–‡ä»¶ï¼ˆExcelï¼‰")
        conf_file = st.file_uploader("ä¸Šä¼ åŒ…å«ä¼šè®®ä¿¡æ¯çš„ Excel æ–‡ä»¶", type=["xlsx"], key="conf", label_visibility="collapsed")
        if conf_file:
            st.success("ä¼šè®®æ–‡ä»¶å·²ä¸Šä¼ ")

    with col2:
        st.subheader("ğŸ“¤ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ï¼ˆPDF / Wordï¼‰")
        paper_file = st.file_uploader("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶", type=["pdf", "doc", "docx"], key="paper", label_visibility="collapsed")
        if paper_file:
            st.success("è®ºæ–‡æ–‡ä»¶å·²ä¸Šä¼ ")

    # åˆ†æç»“æœåŒºå—
    if paper_file:
        st.markdown("---")
        st.subheader("ğŸ“˜ è®ºæ–‡å†…å®¹è¯†åˆ«ä¸å­¦ç§‘æ–¹å‘åˆ†æ")
        title, abstract, keywords = extract_paper_content(paper_file)
        st.markdown(f"**ğŸ“Œ æ ‡é¢˜ï¼š** {title}")
        st.markdown(f"**ğŸ“Œ æ‘˜è¦ï¼š** {abstract}")
        st.markdown(f"**ğŸ“Œ å…³é”®è¯ï¼š** {keywords}")

        heading, subject_result, explanation = analyze_paper_subject(title, abstract, keywords)
        st.markdown(f"### {heading}")
        st.markdown(explanation)

    # åŒ¹é…ä¼šè®®å±•ç¤ºåŒºå—
    if paper_file and conf_file:
        st.markdown("---")
        st.subheader("ğŸ“… ä¼šè®®æ¨èåŒ¹é…ç»“æœ")
        conf_df = pd.read_excel(conf_file)

        matches = match_paper_to_conference(keywords.split(","), conf_df)

        if not matches:
            st.warning("âš ï¸ æœªèƒ½æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„ä¼šè®®ï¼Œä½†ä½ å¯ä»¥å‚è€ƒä»¥ä¸Šå­¦ç§‘æ–¹å‘å¯»æ‰¾æ¥è¿‘é¢†åŸŸçš„ä¼šè®®ã€‚")
        else:
            for row in matches:
                st.markdown(f"#### ğŸ“ ä¼šè®®ç³»åˆ—ï¼š{row.get('ä¼šè®®ç³»åˆ—å')} / {row.get('ä¼šè®®å')}")
                st.markdown(f"- **ä¸»é¢˜æ–¹å‘ï¼š** {row.get('ä¸»é¢˜æ–¹å‘')}")
                st.markdown(f"- **ç»†åˆ†å…³é”®è¯ï¼š** {row.get('ç»†åˆ†å…³é”®è¯')}")
                st.markdown(f"- **æˆªç¨¿æ—¥æœŸï¼š** {row.get('æˆªç¨¿æ—¶é—´')}")
                st.markdown(f"- **åŠ¨æ€å‡ºç‰ˆæ ‡è®°ï¼š** {row.get('åŠ¨æ€å‡ºç‰ˆæ ‡è®°')}")
                link = row.get("å®˜ç½‘é“¾æ¥")
                if isinstance(link, str) and link.startswith("http"):
                    st.markdown(f"- **ä¼šè®®å®˜ç½‘ï¼š** [{link}]({link})")
                else:
                    st.markdown(f"- **ä¼šè®®å®˜ç½‘ï¼š** {link}")
                st.markdown("---")


# -------------------- å¯åŠ¨å…¥å£ --------------------
if __name__ == "__main__":
    main()
