# è¿™æ˜¯ä½ æ‰€è¦æ±‚çš„ Streamlit åº”ç”¨å®Œæ•´ä»£ç ï¼Œæ»¡è¶³ä»¥ä¸‹æ‰€æœ‰æ¡ä»¶ï¼š
# - å·¦ä¾§ä¸ºä¼šè®®æ–‡ä»¶ä¸Šä¼ åŒºï¼Œå³ä¾§ä¸ºè®ºæ–‡æ–‡ä»¶ä¸Šä¼ åŒº
# - ä¸Šä¼ è®ºæ–‡æ–‡ä»¶åç«‹å³è¿›è¡Œå­¦ç§‘æ–¹å‘åˆ†æ
# - ä¿ç•™ä¸Šä¼ ä¼šè®®æ–‡ä»¶åçš„åŒ¹é…åŠŸèƒ½
# - UIæ¸…æ™°ï¼Œåˆ†åŒºåŸŸæ˜¾ç¤ºï¼Œé¿å…æ··æ·†
# - å¢åŠ ä¸Šä¼ åŒºåŸŸé«˜åº¦ä»¥ä¾¿æ‹–æ‹½
# - è§£æPDFæˆ–DOCXè‡ªåŠ¨æå–å†…å®¹

app_code = '''
import streamlit as st
import pandas as pd
import datetime
import io
import fitz  # PyMuPDF
import docx
import time

# æ˜¾ç¤ºé¡µé¢æ ‡é¢˜
st.set_page_config(layout="wide")
st.title("ğŸ“„ æ™ºèƒ½è®ºæ–‡ä¼šè®®åŒ¹é…ä¸å­¦ç§‘åˆ†æç³»ç»Ÿ")

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸé«˜åº¦
UPLOAD_HEIGHT = 300

# è®¡ç®—æˆªç¨¿å‰©ä½™å¤©æ•°
def calculate_days_left(cutoff_date):
    return (cutoff_date - datetime.datetime.now().date()).days

# æå– PDF å†…å®¹
def extract_text_from_pdf(file):
    try:
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text
    except Exception as e:
        return ""

# æå– DOCX å†…å®¹
def extract_text_from_docx(file):
    try:
        doc = docx.Document(file)
        return "\\n".join([para.text for para in doc.paragraphs])
    except Exception as e:
        return ""

# æå–è®ºæ–‡å†…å®¹
def extract_paper_content(file):
    if file.name.endswith(".pdf"):
        return extract_text_from_pdf(file)
    elif file.name.endswith(".docx"):
        return extract_text_from_docx(file)
    else:
        return ""

# ç®€åŒ–çš„å­¦ç§‘åˆ†æå‡½æ•°ï¼ˆæ¨¡æ‹Ÿï¼‰
def analyze_paper_subject(text):
    subjects = {
        "ç”µåŠ›ç³»ç»Ÿ": ["voltage", "power", "grid", "ç”µåŠ›"],
        "æ§åˆ¶ç†è®º": ["control", "strategy", "æ§åˆ¶", "è°ƒèŠ‚"],
        "è®¡ç®—æœºç§‘å­¦": ["algorithm", "neural", "å­¦ä¹ ", "AI", "äººå·¥æ™ºèƒ½"]
    }
    result = {}
    lowered = text.lower()
    total_score = 0

    for subject, keywords in subjects.items():
        score = sum([lowered.count(k.lower()) for k in keywords])
        if score > 0:
            result[subject] = score
            total_score += score

    if not result:
        st.warning("â—æœªèƒ½è¯†åˆ«æ˜ç¡®çš„å­¦ç§‘æ–¹å‘ï¼Œè¯·æ£€æŸ¥è®ºæ–‡å†…å®¹æ˜¯å¦ä¸ºæœ‰æ•ˆæ–‡æœ¬ã€‚")
        return {}

    # å½’ä¸€åŒ–ç™¾åˆ†æ¯”
    for k in result:
        result[k] = round(result[k] / total_score * 100)

    st.subheader("ğŸ“˜ è®ºæ–‡å­¦ç§‘æ–¹å‘åˆ†æ")
    for subject, percent in sorted(result.items(), key=lambda x: x[1], reverse=True):
        st.markdown(f"- **{subject}**ï¼š{percent}%")

    return result

# åŒ¹é…å‡½æ•°
def perform_matching(conference_file, paper_subjects):
    try:
        conference_data = pd.read_excel(conference_file)
        st.success("âœ… ä¼šè®®æ–‡ä»¶åŠ è½½æˆåŠŸ")

        st.subheader("ğŸ” æ¨èåŒ¹é…çš„ä¼šè®®")

        matching_conferences = []
        for index, row in conference_data.iterrows():
            conference_subjects = str(row.get("ä¼šè®®ä¸»é¢˜æ–¹å‘", "")).split(',')
            match_score = 0
            for subject in paper_subjects:
                if subject in conference_subjects:
                    match_score += paper_subjects[subject]

            if match_score > 0:
                matching_conferences.append({
                    "ä¼šè®®å": f"{row.get('ä¼šè®®ç³»åˆ—å', '')} - {row.get('ä¼šè®®å', '')}",
                    "é“¾æ¥": row.get('å®˜ç½‘é“¾æ¥', ''),
                    "å‡ºç‰ˆ": row.get('åŠ¨æ€å‡ºç‰ˆæ ‡è®°', ''),
                    "æˆªç¨¿": row.get('æˆªç¨¿æ—¶é—´', ''),
                    "å‰©ä½™å¤©æ•°": calculate_days_left(row.get('æˆªç¨¿æ—¶é—´')) if not pd.isnull(row.get('æˆªç¨¿æ—¶é—´')) else "æœªçŸ¥",
                    "åŒ¹é…æ–¹å‘": row.get('ä¼šè®®ä¸»é¢˜æ–¹å‘', '')
                })

        if matching_conferences:
            for conf in matching_conferences:
                st.markdown(f"### ğŸ¯ {conf['ä¼šè®®å']}")
                st.markdown(f"- ğŸ”— [ä¼šè®®å®˜ç½‘]({conf['é“¾æ¥']})")
                st.markdown(f"- ğŸ“… æˆªç¨¿æ—¶é—´ï¼š{conf['æˆªç¨¿']}ï¼ˆè¿˜æœ‰ {conf['å‰©ä½™å¤©æ•°']} å¤©ï¼‰")
                st.markdown(f"- ğŸ§© åŒ¹é…æ–¹å‘ï¼š{conf['åŒ¹é…æ–¹å‘']}")
                st.markdown(f"- ğŸ“¤ å‡ºç‰ˆï¼š{conf['å‡ºç‰ˆ']}")
        else:
            st.warning("âš ï¸ å½“å‰è®ºæ–‡æ–¹å‘æœªå®Œå…¨åŒ¹é…ä»»ä½•ä¼šè®®ï¼Œå¯å‚è€ƒæ¨èæ–¹å‘ç»§ç»­æŸ¥æ‰¾ã€‚")

    except Exception as e:
        st.error(f"åŠ è½½ä¼šè®®æ–‡ä»¶å¤±è´¥ï¼š{e}")

# --- UI åˆ†åˆ—å¸ƒå±€ ---
left, right = st.columns(2)

with left:
    st.markdown("## ğŸ“ ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
    conference_file = st.file_uploader("ä¸Šä¼ ä¼šè®®Excelæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰", type=["xlsx"], label_visibility="collapsed", key="conf", accept_multiple_files=False, help="è¯·ä¸Šä¼ å«æœ‰ä¼šè®®ä¸»é¢˜æ–¹å‘ç­‰å­—æ®µçš„Excelæ–‡ä»¶", height=UPLOAD_HEIGHT)

with right:
    st.markdown("## ğŸ“ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
    paper_file = st.file_uploader("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ï¼ˆPDFæˆ–DOCXï¼‰", type=["pdf", "docx"], label_visibility="collapsed", key="paper", accept_multiple_files=False, help="ä¸Šä¼ åå°†è‡ªåŠ¨è¿›è¡Œè®ºæ–‡åˆ†æ", height=UPLOAD_HEIGHT)

# --- åˆ†æé€»è¾‘ ---
if paper_file:
    with st.spinner("æ­£åœ¨åˆ†æè®ºæ–‡å†…å®¹..."):
        content = extract_paper_content(paper_file)
        if content.strip():
            subjects = analyze_paper_subject(content)
            if conference_file and subjects:
                perform_matching(conference_file, subjects)
        else:
            st.error("è®ºæ–‡æ–‡ä»¶å†…å®¹æ— æ³•è¯»å–ï¼Œè¯·ä¸Šä¼ æœ‰æ•ˆçš„PDFæˆ–Wordæ–‡æ¡£ã€‚")
else:
    st.info("ğŸ“Œ è¯·ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ä»¥å¼€å§‹åˆ†æ")
'''

with open("/mnt/data/app.py", "w", encoding="utf-8") as f:
    f.write(app_code)

"/mnt/data/app.py å·²ç”Ÿæˆï¼Œå¯å¤åˆ¶è‡³ GitHub é¡¹ç›®ä¸­ç›´æ¥æ›¿æ¢éƒ¨ç½²ä½¿ç”¨ã€‚"
