import streamlit as st
import pandas as pd
import datetime
import io
import time
import re
from docx import Document
import fitz  # PyMuPDFï¼Œç”¨äºPDFè§£æ
import requests
from collections import Counter

# ä½¿ç”¨ç¬¬ä¸‰æ–¹APIç¿»è¯‘ï¼ˆæ— éœ€å®‰è£…åº“ï¼‰
def translate_text(text, target_lang="zh"):
    try:
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            "client": "gtx",
            "sl": "en",
            "tl": target_lang,
            "dt": "t",
            "q": text
        }
        response = requests.get(url, params=params)
        result = response.json()
        return "".join([item[0] for item in result[0]])
    except:
        return "(ç¿»è¯‘å¤±è´¥)"

# æå– PDF æ–‡æœ¬
def extract_text_from_pdf(file):
    try:
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text
    except Exception as e:
        st.error(f"PDFè§£æå¤±è´¥: {e}")
        return ""

# æå– Word æ–‡æœ¬
def extract_text_from_word(file):
    try:
        document = Document(file)
        text = "\n".join([para.text for para in document.paragraphs])
        return text
    except Exception as e:
        st.error(f"Wordè§£æå¤±è´¥: {e}")
        return ""

# æå–è®ºæ–‡é¢˜ç›®ï¼ˆæ›´æ™ºèƒ½çš„è¯†åˆ«ï¼‰
def extract_title(text):
    lines = text.split('\n')
    title_candidates = []
    for i, line in enumerate(lines):
        cleaned_line = line.strip()
        if 15 < len(cleaned_line) < 250:  # æ›´ä¸¥æ ¼çš„é•¿åº¦é™åˆ¶
            # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å¤§å†™æˆ–é¦–å­—æ¯å¤§å†™æ¯”ä¾‹é«˜
            upper_ratio = sum(1 for c in cleaned_line if c.isupper()) / len(cleaned_line)
            if upper_ratio > 0.6 or (cleaned_line and cleaned_line[0].isupper() and not cleaned_line[0].isdigit() and upper_ratio > 0.3):
                title_candidates.append((i, cleaned_line))
            # æŸ¥æ‰¾å¯èƒ½åŒ…å«æ ‡é¢˜çš„å¸¸è§çŸ­è¯­åçš„è¡Œ
            elif i > 0 and re.search(r"(title|è®ºæ–‡é¢˜ç›®)[:ï¼š]", lines[i-1], re.IGNORECASE) and cleaned_line:
                title_candidates.append((i, cleaned_line))

    if title_candidates:
        # è¿”å›ç¬¬ä¸€ä¸ªçœ‹èµ·æ¥æœ€åƒæ ‡é¢˜ä¸”ä½ç½®é å‰çš„
        return min(title_candidates, key=lambda x: x[0])[1]
    elif lines:
        return lines[0].strip()
    else:
        return "æ— æ³•è¯†åˆ«é¢˜ç›®"

# æå–å…³é”®è¯ï¼ˆæ›´å…¨é¢çš„è¯†åˆ«ï¼‰
def extract_keywords(text):
    keywords = set()
    patterns = [
        r"(?i)(Keywords|Index Terms)[:ï¼š]\s*([^\n]+)",
        r"(?i)å…³é”®è¯[:ï¼š]\s*([^\n]+)"
    ]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            keyword_str = match.group(2).strip()
            # æŒ‰ç…§é€—å·ã€åˆ†å·æˆ–æ¢è¡Œç¬¦åˆ†å‰²å…³é”®è¯
            split_keywords = re.split(r'[;,ï¼Œ\n]\s*', keyword_str)
            keywords.update(split_keywords)
    return ", ".join(filter(None, keywords)) # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å¹¶ç”¨é€—å·è¿æ¥

# å­¦ç§‘æ–¹å‘åˆ†æï¼ˆåŸºäºæ›´å…¨é¢çš„å…³é”®è¯ï¼‰
def analyze_paper_subject(text):
    text = text.lower()
    subject_keywords = {
        "äººåŠ›èµ„æºç®¡ç†": ["äººåŠ›èµ„æºç®¡ç†", "å‘˜å·¥æ‹›è˜", "ç»©æ•ˆè€ƒæ ¸", "è–ªé…¬ç¦åˆ©", "äººæ‰å‘å±•", "åŠ³åŠ¨å…³ç³»", "ç»„ç»‡è¡Œä¸ºå­¦", "human resource management", "employee recruitment", "performance appraisal", "compensation and benefits", "talent development", "labor relations", "organizational behavior"],
        "æ•°å­—åŒ–è½¬å‹": ["æ•°å­—åŒ–", "æ•°å­—åŒ–è½¬å‹", "æ•°å­—ç»æµ", "äº§ä¸šæ•°å­—åŒ–", "ä¼ä¸šæ•°å­—åŒ–", "æ™ºèƒ½åˆ¶é€ ", "å¤§æ•°æ®åˆ†æ", "äº‘è®¡ç®—åº”ç”¨", "äººå·¥æ™ºèƒ½èµ‹èƒ½", "ç‰©è”ç½‘æŠ€æœ¯", "digitalization", "digital transformation", "digital economy", "industrial digitalization", "enterprise digitalization", "smart manufacturing", "big data analytics", "cloud computing applications", "ai empowerment", "iot technology"],
        "ä¼šè®¡å­¦": ["ä¼šè®¡å­¦", "è´¢åŠ¡ä¼šè®¡", "ç®¡ç†ä¼šè®¡", "å®¡è®¡", "ç¨åŠ¡", "ä¼šè®¡å‡†åˆ™", "è´¢åŠ¡æŠ¥è¡¨åˆ†æ", "æˆæœ¬ä¼šè®¡", "å†…éƒ¨æ§åˆ¶", "ä¼šè®¡ä¿¡æ¯ç³»ç»Ÿ", "accounting", "financial accounting", "management accounting", "auditing", "taxation", "accounting standards", "financial statement analysis", "cost accounting", "internal control", "accounting information systems"],
        "å•†ä¸šç»Ÿè®¡å­¦": ["å•†ä¸šç»Ÿè®¡å­¦", "ç»Ÿè®¡åˆ†æ", "æ•°æ®åˆ†æ", "å›å½’åˆ†æ", "æ—¶é—´åºåˆ—åˆ†æ", "å¤šå…ƒç»Ÿè®¡åˆ†æ", "å¸‚åœºè°ƒæŸ¥", "é¢„æµ‹æ–¹æ³•", "å•†åŠ¡ç»Ÿè®¡", "statistical analysis", "data analysis", "regression analysis", "time series analysis", "multivariate statistical analysis", "market research", "forecasting methods", "business statistics"],
        "ç»æµå­¦": ["ç»æµå­¦", "å®è§‚ç»æµå­¦", "å¾®è§‚ç»æµå­¦", "å›½é™…ç»æµå­¦", "å‘å±•ç»æµå­¦", "æ”¿æ²»ç»æµå­¦", "è®¡é‡ç»æµå­¦", "è¡Œä¸ºç»æµå­¦", "äº§ä¸šç»æµå­¦", "åŒºåŸŸç»æµå­¦", "economics", "macroeconomics", "microeconomics", "international economics", "development economics", "political economy", "econometrics", "behavioral economics", "industrial economics", "regional economics"],
        "ç®¡ç†å­¦": ["ç®¡ç†å­¦", "æˆ˜ç•¥ç®¡ç†", "è¿è¥ç®¡ç†", "å¸‚åœºè¥é”€", "ç»„ç»‡ç®¡ç†", "é¡¹ç›®ç®¡ç†", "åˆ›æ–°ç®¡ç†", "è´¨é‡ç®¡ç†", "ä¾›åº”é“¾ç®¡ç†", "äººåŠ›èµ„æºç®¡ç†", "management", "strategic management", "operations management", "marketing", "organizational management", "project management", "innovation management", "quality management", "supply chain management", "human resource management"],
        "ç»æµä¸ç®¡ç†": ["ç»æµä¸ç®¡ç†", "ç»æµç®¡ç†", "å·¥å•†ç®¡ç†", "æŠ€æœ¯ç»æµä¸ç®¡ç†", "å†œä¸šç»æµç®¡ç†", "æ—…æ¸¸ç»æµç®¡ç†", "é¡¹ç›®ç»æµç®¡ç†", "economic and management", "business administration", "technical economics and management", "agricultural economics and management", "tourism economics and management", "project economics and management"],
        "é‡‘èå­¦": ["é‡‘èå­¦", "è´§å¸é“¶è¡Œå­¦", "å›½é™…é‡‘è", "æŠ•èµ„å­¦", "å…¬å¸é‡‘è", "é‡‘èå¸‚åœº", "é‡‘èå·¥ç¨‹", "é£é™©ç®¡ç†", "ä¿é™©å­¦", "è¯åˆ¸æŠ•èµ„", "finance", "monetary economics", "international finance", "investment", "corporate finance", "financial markets", "financial engineering", "risk management", "insurance", "securities investment"],
        "ç®¡ç†ç§‘å­¦ä¸å·¥ç¨‹": ["ç®¡ç†ç§‘å­¦ä¸å·¥ç¨‹", "ç³»ç»Ÿå·¥ç¨‹", "è¿ç­¹å­¦", "å†³ç­–åˆ†æ", "ä¿¡æ¯ç®¡ç†", "å·¥ä¸šå·¥ç¨‹", "ç‰©æµå·¥ç¨‹", "é¡¹ç›®ç®¡ç†", "æŠ€æœ¯ç®¡ç†", "åˆ›æ–°ç®¡ç†", "management science and engineering", "systems engineering", "operations research", "decision analysis", "information management", "industrial engineering", "logistics engineering", "project management", "technology management", "innovation management"],
        "ä¼šè®¡ä¸é‡‘è": ["ä¼šè®¡ä¸é‡‘è", "è´¢åŠ¡ä¸é‡‘è", "ä¼šè®¡é‡‘è", "é‡‘èä¼šè®¡", "accounting and finance", "finance and accounting", "financial accounting and finance"],
        "é‡‘èç§‘æŠ€": ["é‡‘èç§‘æŠ€", "FinTech", "åŒºå—é“¾", "äººå·¥æ™ºèƒ½é‡‘è", "å¤§æ•°æ®é‡‘è", "ç§»åŠ¨æ”¯ä»˜", "æ•°å­—è´§å¸", "æ™ºèƒ½æŠ•é¡¾", "ç›‘ç®¡ç§‘æŠ€", "é‡‘èæ•°å­—åŒ–", "blockchain", "ai finance", "big data finance", "mobile payment", "digital currency", "robo-advisor", "regtech", "digital finance"],
        "å•†ä¸šæ™ºèƒ½": ["å•†ä¸šæ™ºèƒ½", "BI", "æ•°æ®å¯è§†åŒ–", "æ•°æ®ä»“åº“", "OLAP", "å•†ä¸šåˆ†æ", "å†³ç­–æ”¯æŒç³»ç»Ÿ", "æ•°æ®æŒ–æ˜", "é¢„æµ‹åˆ†æ", "ç»©æ•ˆç®¡ç†", "business intelligence", "data visualization", "data warehouse", "online analytical processing", "business analytics", "decision support systems", "data mining", "predictive analytics", "performance management"],
        "ç§‘æŠ€é‡‘è": ["ç§‘æŠ€é‡‘è", "æŠ€æœ¯é©±åŠ¨é‡‘è", "é‡‘èåˆ›æ–°", "äº’è”ç½‘é‡‘è", "æ•°å­—æ™®æƒ é‡‘è", "å¼€æ”¾é“¶è¡Œ", "tech finance", "technology-driven finance", "financial innovation", "internet finance", "digital inclusive finance", "open banking"],
        "ç®¡ç†ç§‘å­¦": ["ç®¡ç†ç§‘å­¦", "å†³ç­–ç§‘å­¦", "è¡Œä¸ºç§‘å­¦", "ç»„ç»‡ç§‘å­¦", "å…¬å…±ç®¡ç†", "æ•™è‚²ç®¡ç†", "åŒ»ç–—ç®¡ç†", "ç§‘å­¦ç®¡ç†", "management science", "decision science", "behavioral science", "organizational science", "public administration", "educational management", "healthcare management", "scientific management"],
        "ç»æµå‘å±•": ["ç»æµå‘å±•", "å¯æŒç»­å‘å±•", "åŒºåŸŸå‘å±•", "å†œæ‘å‘å±•", "äº§ä¸šå‘å±•", "åˆ›æ–°é©±åŠ¨å‘å±•", "ç»¿è‰²å‘å±•", "åŒ…å®¹æ€§å‘å±•", "é«˜è´¨é‡å‘å±•", "economic development", "sustainable development", "regional development", "rural development", "industrial development", "innovation-driven development", "green development", "inclusive development", "high-quality development"],
        "ç»æµä½“ç³»": ["ç»æµä½“ç³»", "å¸‚åœºç»æµä½“ç³»", "ç¤¾ä¼šä¸»ä¹‰å¸‚åœºç»æµ", "å®è§‚è°ƒæ§ä½“ç³»", "å¼€æ”¾å‹ç»æµä½“ç³»", "ç°ä»£åŒ–ç»æµä½“ç³»", "economic system", "market economy system", "socialist market economy", "macro-control system", "open economic system", "modern economic system"],
        "äº§ä¸šç»æµ": ["äº§ä¸šç»æµ", "å·¥ä¸šç»æµ", "å†œä¸šç»æµ", "æœåŠ¡ä¸šç»æµ", "æ•°å­—ç»æµ", "å¹³å°ç»æµ", "çŸ¥è¯†ç»æµ", "ç»¿è‰²ç»æµ", "åˆ›æ„ç»æµ", "äº§ä¸šç»“æ„", "industrial economics", "agricultural economics", "service industry economics", "digital economy", "platform economy", "knowledge economy", "green economy", "creative economy", "industrial structure"],
        "æ•°æ®åˆ†æ": ["æ•°æ®åˆ†æ", "æ•°æ®æŒ–æ˜", "ç»Ÿè®¡åˆ†æ", "å•†ä¸šåˆ†æ", "æ–‡æœ¬åˆ†æ", "ç¤¾äº¤ç½‘ç»œåˆ†æ", "ç”¨æˆ·è¡Œä¸ºåˆ†æ", "é¢„æµ‹åˆ†æ", "æ•°æ®å¯è§†åŒ–", "æ•°æ®å»ºæ¨¡", "data analysis", "data mining", "statistical analysis", "business analytics", "text analysis", "social network analysis", "user behavior analysis", "predictive analytics", "data visualization", "data modeling"],
        "æ•°æ®ç§‘å­¦": ["æ•°æ®ç§‘å­¦", "æ•°æ®ç§‘å­¦å®¶", "å¤§æ•°æ®åˆ†æ", "æœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "æ•°æ®å·¥ç¨‹", "æ•°æ®ç®¡ç†", "æ•°æ®ä¼¦ç†", "æ•°æ®æ²»ç†", "æ•°æ®äº§å“", "data science", "data scientist", "big data analytics", "machine learning", "artificial intelligence", "data engineering", "data management", "data ethics", "data governance", "data products"],
        "å¯è§†åŒ–": ["å¯è§†åŒ–", "æ•°æ®å¯è§†åŒ–", "ä¿¡æ¯å¯è§†åŒ–", "ç§‘å­¦å¯è§†åŒ–", "äº¤äº’å¼å¯è§†åŒ–", "å¯è§†åŒ–åˆ†æ", "å¯è§†åŒ–å·¥å…·", "å¯è§†åŒ–è®¾è®¡", "å¯è§†åŒ–æ–¹æ³•", "å¯è§†åŒ–æŠ€æœ¯", "visualization", "data visualization", "information visualization", "scientific visualization", "interactive visualization", "visual analytics", "visualization tools", "visualization design", "visualization methods", "visualization technology"],
        "æœºå™¨å­¦ä¹ ": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "å¼ºåŒ–å­¦ä¹ ", "ç›‘ç£å­¦ä¹ ", "æ— ç›‘ç£å­¦ä¹ ", "æ¨¡å‹è®­ç»ƒ", "ç‰¹å¾å·¥ç¨‹", "ç¥ç»ç½‘ç»œ", "å·ç§¯ç¥ç»ç½‘ç»œ", "å¾ªç¯ç¥ç»ç½‘ç»œ", "machine learning", "deep learning", "reinforcement learning", "supervised learning", "unsupervised learning", "model training", "feature engineering", "neural networks", "convolutional neural networks", "recurrent neural networks"],
        "çŸ³æ²¹å·¥ç¨‹": ["çŸ³æ²¹å·¥ç¨‹", "æ²¹æ°”å‹˜æ¢", "æ²¹æ°”é’»äº•", "æ²¹æ°”å¼€é‡‡", "æ²¹è—å·¥ç¨‹", "çŸ³æ²¹åœ°è´¨", "æ²¹ç”°åŒ–å­¦", "é‡‡æ²¹å·¥ç¨‹", "å¤©ç„¶æ°”å·¥ç¨‹", "ç®¡é“è¾“é€", "petroleum engineering", "oil and gas exploration", "oil and gas drilling", "oil and gas production", "reservoir engineering", "petroleum geology", "oilfield chemistry", "production engineering", "natural gas engineering", "pipeline transportation"],
        "è®¡ç®—æœº": ["è®¡ç®—æœº", "è®¡ç®—æœºç§‘å­¦", "è®¡ç®—æœºæŠ€æœ¯", "è®¡ç®—æœºåº”ç”¨", "è®¡ç®—æœºç³»ç»Ÿ", "è®¡ç®—æœºç½‘ç»œ", "è®¡ç®—æœºç»„æˆ", "è®¡ç®—æœºä½“ç³»ç»“æ„", "è®¡ç®—æœºå›¾å½¢å­¦", "è®¡ç®—æœºè§†è§‰", "computer", "computer science", "computer technology", "computer applications", "computer systems", "computer networks", "computer organization", "computer architecture", "computer graphics", "computer vision"],
        "è‡ªåŠ¨åŒ–": ["è‡ªåŠ¨åŒ–", "å·¥ä¸šè‡ªåŠ¨åŒ–", "æ™ºèƒ½è‡ªåŠ¨åŒ–", "æœºå™¨äººæŠ€æœ¯", "æ§åˆ¶ç³»ç»Ÿ", "è¿‡ç¨‹æ§åˆ¶", "è¿åŠ¨æ§åˆ¶", "è‡ªåŠ¨åŒ–ä»ªè¡¨", "è‡ªåŠ¨åŒ–è®¾å¤‡", "è‡ªåŠ¨åŒ–ç”Ÿäº§çº¿", "automation", "industrial automation", "intelligent automation", "robotics", "control systems", "process control", "motion control", "automation instruments", "automation equipment", "automated production lines"],
        "AIæ¨¡å‹": ["AIæ¨¡å‹", "äººå·¥æ™ºèƒ½æ¨¡å‹", "æœºå™¨å­¦ä¹ æ¨¡å‹", "æ·±åº¦å­¦ä¹ æ¨¡å‹", "è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹", "è®¡ç®—æœºè§†è§‰æ¨¡å‹", "ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ", "Transformeræ¨¡å‹", "é¢„è®­ç»ƒæ¨¡å‹", "æ¨¡å‹éƒ¨ç½²", "ai model", "artificial intelligence model", "machine learning model", "deep learning model", "natural language processing model", "computer vision model", "generative adversarial network", "transformer model", "pre-trained model", "model deployment"],
        "äººå·¥æ™ºèƒ½": ["äººå·¥æ™ºèƒ½", "AI", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "è‡ªç„¶è¯­è¨€å¤„ç†", "è®¡ç®—æœºè§†è§‰", "çŸ¥è¯†å›¾è°±", "æ™ºèƒ½Agent", "ä¸“å®¶ç³»ç»Ÿ", "æ¨ç†", "artificial intelligence", "machine learning", "deep learning", "natural language processing", "computer vision", "knowledge graph", "intelligent agent", "expert system", "reasoning"],
        "è‡ªç„¶è¯­è¨€å¤„ç†": ["è‡ªç„¶è¯­è¨€å¤„ç†", "NLP", "æ–‡æœ¬æŒ–æ˜", "è¯­ä¹‰åˆ†æ", "æœºå™¨ç¿»è¯‘", "æƒ…æ„Ÿåˆ†æ", "é—®ç­”ç³»ç»Ÿ", "ä¿¡æ¯æŠ½å–", "æ–‡æœ¬ç”Ÿæˆ", "è¯­è¨€æ¨¡å‹", "natural language processing", "text mining", "semantic analysis", "machine translation", "sentiment analysis", "question answering system", "information extraction", "text generation", "language model"],
        "è®¡ç®—æœºè§†è§‰": ["è®¡ç®—æœºè§†è§‰", "CV", "å›¾åƒè¯†åˆ«", "ç›®æ ‡æ£€æµ‹", "å›¾åƒåˆ†å‰²", "è§†é¢‘åˆ†æ", "äººè„¸è¯†åˆ«", "ä¸‰ç»´è§†è§‰", "å›¾åƒå¤„ç†", "è§†è§‰SLAM", "computer vision", "image recognition", "object detection", "image segmentation", "video analysis", "face recognition", "3d vision", "image processing", "visual slam"],
        "æ¨èç³»ç»Ÿ": ["æ¨èç³»ç»Ÿ", "ååŒè¿‡æ»¤", "å†…å®¹æ¨è", "çŸ¥è¯†å›¾è°±æ¨è", "æ·±åº¦å­¦ä¹ æ¨è", "ä¸ªæ€§åŒ–æ¨è", "æ¨èç®—æ³•", "ç”¨æˆ·ç”»åƒ", "ç‰©å“ç”»åƒ", "æ¨èè§£é‡Š", "recommender system", "collaborative filtering", "content-based recommendation", "knowledge graph recommendation", "deep learning recommendation", "personalized recommendation", "recommendation algorithm", "user profile", "item profile", "recommendation explanation"],
        "æ•™è‚²æ”¿ç­–": ["æ•™è‚²æ”¿ç­–"], "ç¤¾ä¼šå­¦": ["ç¤¾ä¼šå­¦"], "æ•™è‚²ç®¡ç†": ["æ•™è‚²ç®¡ç†"], "å¿ƒç†å­¦": ["å¿ƒç†å­¦"],
        "å­¦ç§‘æ•™è‚²": ["å­¦ç§‘æ•™è‚²", "åˆä¸­", "é«˜ä¸­", "é«˜ç­‰æ•™è‚²"],
        "å›½é™…å…³ç³»": ["å›½é™…å…³ç³»", "æ”¿æ²»å­¦", "æ³•", "å›½é™…ç»„ç»‡"],
        "å›½é™…æ³•": ["å›½é™…æ³•", "åŠ³åŠ¨æ³•", "åˆ‘æ³•"],
        "ç”Ÿç‰©å­¦": ["ç”Ÿç‰©å­¦", "åŠ¨ç‰©å­¦", "æ˜†è™«å­¦", "åŒ»å­¦", "ç”Ÿæ€å­¦", "å¾®ç”Ÿç‰©å­¦"],
        "ç¯å¢ƒ": ["ç¯å¢ƒ", "ç”Ÿæ€", "åœ°ç†å­¦", "ç¯å¢ƒç§‘å­¦"],
        "ä¼ æ„Ÿå™¨": ["ä¼ æ„Ÿå™¨", "æ•°æ®åˆ†æ", "åœ°çƒç‰©ç†å­¦"],
        "ç®—æ³•": ["ç®—æ³•", "æ•°å­¦", "ç‰©ç†", "å»ºæ¨¡", "æ§åˆ¶"],
        "æœºæ¢°": ["æœºæ¢°", "ç”µå­", "ç”µæ°”", "ææ–™"],
        "é€šä¿¡": ["é€šä¿¡", "ç‰©è”ç½‘", "äº’è”ç½‘", "æ— çº¿", "å…‰çº¤"],
        "è¯­è¨€": ["è¯­è¨€", "æ–‡å­¦", "ä¼ åª’", "è‰ºæœ¯"]
    }
    subject_scores = Counter()
    for subject, keywords in subject_keywords.items():
        for keyword in keywords:
            subject_scores[subject] += text.lower().count(keyword.lower()) # å¿½ç•¥å¤§å°å†™åŒ¹é…

    total_score = sum(subject_scores.values())
    if total_score > 0:
        normalized_scores = {k: v / total_score * 100 for k, v in subject_scores.items()}
        return dict(normalized_scores.most_common())
    else:
        return {"æ— æ³•è¯†åˆ«å­¦ç§‘æ–¹å‘": 100}

# è®¡ç®—å‰©ä½™å¤©æ•°
def calculate_days_left(cutoff_date):
    return (cutoff_date - datetime.datetime.now().date()).days

# ä¸»å‡½æ•°
def main():
    st.set_page_config(layout="wide")
    st.title("è®ºæ–‡ä¸ä¼šè®®åŒ¹é…ç³»ç»Ÿ")
    col1, col2 = st.columns(2)
    with col1:
        st.header("ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
        conference_file = st.file_uploader("ä¸Šä¼ ä¼šè®® Excel æ–‡ä»¶", type=["xlsx"], key="conf")
    with col2:
        st.header("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
        paper_file = st.file_uploader("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ (PDF æˆ– Word)", type=["pdf", "docx"], key="paper")

    # å¦‚æœä¸Šä¼ äº†è®ºæ–‡æ–‡ä»¶ï¼Œç«‹å³åˆ†æ
    if paper_file:
        st.markdown("## ğŸ“„ è®ºæ–‡å†…å®¹è§£æç»“æœ")
        file_text = ""
        if paper_file.name.endswith(".pdf"):
            file_text = extract_text_from_pdf(paper_file)
        elif paper_file.name.endswith(".docx"):
            file_text = extract_text_from_word(paper_file)
        if not file_text.strip():
            st.error("æœªèƒ½æˆåŠŸæå–è®ºæ–‡å†…å®¹")
            return
        # æå–é¢˜ç›®ä¸å…³é”®è¯
        title = extract_title(file_text)
        keywords = extract_keywords(file_text)
        # ç¿»è¯‘ç»“æœ
        title_zh = translate_text
