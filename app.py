import streamlit as st
import pandas as pd
import datetime
import io
import time
import re
from docx import Document
import fitz  # PyMuPDFï¼Œç”¨äºPDFè§£æ
import requests

# ä½¿ç”¨ç¬¬ä¸‰æ–¹APIç¿»è¯‘ï¼ˆæ— éœ€å®‰è£…åº“ï¼‰
def translate_text(text, target_lang="zh"):
    try:
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            "client": "gtx",
            "sl": "en",
            "tl": target_lang,
            "dt": "t",
            "q": text
        }
        response = requests.get(url, params=params)
        result = response.json()
        return "".join([item[0] for item in result[0]])
    except:
        return "(ç¿»è¯‘å¤±è´¥)"

# æå– PDF æ–‡æœ¬
def extract_text_from_pdf(file):
    try:
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text
    except Exception as e:
        st.error(f"PDFè§£æå¤±è´¥: {e}")
        return ""

# æå– Word æ–‡æœ¬
def extract_text_from_word(file):
    try:
        document = Document(file)
        text = "\n".join([para.text for para in document.paragraphs])
        return text
    except Exception as e:
        st.error(f"Wordè§£æå¤±è´¥: {e}")
        return ""

# æå–è®ºæ–‡é¢˜ç›®
def extract_title(text):
    lines = text.split('\n')
    for line in lines:
        if 5 < len(line) < 200 and line.strip().istitle():
            return line.strip()
    return lines[0].strip() if lines else "æ— æ³•è¯†åˆ«é¢˜ç›®"

# æå–å…³é”®è¯
def extract_keywords(text):
    patterns = [r"(?i)(Keywords|Index Terms)[:ï¼š]?\s*(.*)"]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(2)
    return "æ— æ³•è¯†åˆ«å…³é”®è¯"

# æ¨¡æ‹Ÿå­¦ç§‘åˆ†æï¼ˆä½ å¯ä»¥æ¢æˆæ¨¡å‹ï¼‰
def analyze_paper_subject(text):
    subjects = {
        "ç”µåŠ›ç³»ç»Ÿ": 40,
        "æ§åˆ¶ç†è®º": 35,
        "è®¡ç®—æœºç§‘å­¦": 25
    }
    return subjects

# è®¡ç®—å‰©ä½™å¤©æ•°
def calculate_days_left(cutoff_date):
    return (cutoff_date - datetime.datetime.now().date()).days

# ä¸»å‡½æ•°
def main():
    st.set_page_config(layout="wide")
    st.title("è®ºæ–‡ä¸ä¼šè®®åŒ¹é…ç³»ç»Ÿ")

    col1, col2 = st.columns(2)

    with col1:
        st.header("ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
        conference_file = st.file_uploader("ä¸Šä¼ ä¼šè®® Excel æ–‡ä»¶", type=["xlsx"], key="conf")

    with col2:
        st.header("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
        paper_file = st.file_uploader("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ (PDF æˆ– Word)", type=["pdf", "docx"], key="paper")

    # å¦‚æœä¸Šä¼ äº†è®ºæ–‡æ–‡ä»¶ï¼Œç«‹å³åˆ†æ
    if paper_file:
        st.markdown("## ğŸ“„ è®ºæ–‡å†…å®¹è§£æç»“æœ")
        file_text = ""
        if paper_file.name.endswith(".pdf"):
            file_text = extract_text_from_pdf(paper_file)
        elif paper_file.name.endswith(".docx"):
            file_text = extract_text_from_word(paper_file)

        if not file_text.strip():
            st.error("æœªèƒ½æˆåŠŸæå–è®ºæ–‡å†…å®¹")
            return

        # æå–é¢˜ç›®ä¸å…³é”®è¯
        title = extract_title(file_text)
        keywords = extract_keywords(file_text)

        # ç¿»è¯‘ç»“æœ
        title_zh = translate_text(title)
        keywords_zh = translate_text(keywords)

        st.subheader("è®ºæ–‡é¢˜ç›®")
        st.write(f"**ä¸­æ–‡ï¼š** {title_zh}")
        st.write(f"**è‹±æ–‡ï¼š** {title}")

        st.subheader("å…³é”®è¯")
        st.write(f"**ä¸­æ–‡ï¼š** {keywords_zh}")
        st.write(f"**è‹±æ–‡ï¼š** {keywords}")

        # å­¦ç§‘åˆ†æ
        st.subheader("å­¦ç§‘æ–¹å‘åˆ†æ")
        subjects = analyze_paper_subject(file_text)
        for subject, percent in subjects.items():
            st.write(f"- {subject}: {percent}%")

        # å¦‚æœä¼šè®®æ–‡ä»¶ä¹Ÿä¸Šä¼ äº†ï¼Œè¿›è¡ŒåŒ¹é…
        if conference_file:
            try:
                conf_data = pd.read_excel(conference_file)
                st.markdown("## ğŸ¯ åŒ¹é…æ¨èçš„ä¼šè®®")
                matches = []
                for _, row in conf_data.iterrows():
                    conf_subjects = row.get('ä¼šè®®ä¸»é¢˜æ–¹å‘', '')
                    if not conf_subjects:
                        continue
                    conf_list = [x.strip() for x in conf_subjects.split(',')]
                    score = sum([subjects.get(s, 0) for s in conf_list])
                    if score > 0:
                        matches.append((score, row))

                matches.sort(reverse=True, key=lambda x: x[0])
                if matches:
                    for score, row in matches[:5]:
                        st.write(f"### âœ… æ¨èä¼šè®®: {row['ä¼šè®®ç³»åˆ—å']} - {row['ä¼šè®®å']}")
                        st.write(f"- ä¼šè®®æ–¹å‘: {row['ä¼šè®®ä¸»é¢˜æ–¹å‘']}")
                        st.write(f"- åŒ¹é…å¾—åˆ†: {score}")
                        st.write(f"- å®˜ç½‘é“¾æ¥: [{row['å®˜ç½‘é“¾æ¥']}]({row['å®˜ç½‘é“¾æ¥']})")
                        if 'æˆªç¨¿æ—¶é—´' in row and not pd.isna(row['æˆªç¨¿æ—¶é—´']):
                            cutoff = row['æˆªç¨¿æ—¶é—´']
                            if isinstance(cutoff, pd.Timestamp):
                                days_left = calculate_days_left(cutoff.date())
                                st.write(f"- æˆªç¨¿æ—¶é—´: {cutoff.date()}ï¼ˆè¿˜æœ‰ {days_left} å¤©ï¼‰")
                        st.markdown("---")
                else:
                    st.info("æœªåŒ¹é…åˆ°é€‚åˆçš„ä¼šè®®ï¼Œè¯·æ ¹æ®å­¦ç§‘æ–¹å‘è‡ªè¡ŒæŸ¥æ‰¾ã€‚")
            except Exception as e:
                st.error(f"ä¼šè®®æ–‡ä»¶è§£æå¤±è´¥ï¼š{e}")

if __name__ == "__main__":
    main()
