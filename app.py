import streamlit as st
import pandas as pd
import datetime
import io
import time
import fitz  # PDF è§£æ
import docx  # Word è§£æ
import re
import requests  # ç”¨äºåœ¨çº¿ç¿»è¯‘

# ç¿»è¯‘å‡½æ•°ï¼ˆé€šè¿‡ Google Translate Web æ¥å£ï¼‰
def translate_text(text, source='zh', target='en'):
    try:
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            "client": "gtx",
            "sl": source,
            "tl": target,
            "dt": "t",
            "q": text
        }
        response = requests.get(url, params=params)
        if response.status_code == 200:
            result = response.json()
            return result[0][0][0]
        else:
            return "[ç¿»è¯‘å¤±è´¥]"
    except:
        return "[ç¿»è¯‘é”™è¯¯]"

def calculate_days_left(cutoff_date):
    return (cutoff_date - datetime.datetime.now().date()).days

def upload_conference_file():
    uploaded_file = st.file_uploader("ä¸Šä¼ ä¼šè®®æ–‡ä»¶", type=["xlsx"])
    return uploaded_file

def upload_paper_file():
    uploaded_file = st.file_uploader("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶", type=["pdf", "docx"])
    return uploaded_file

def extract_text_from_pdf(pdf_file):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    text = ""
    for page in doc:
        text += page.get_text("text")
    return text

def extract_text_from_docx(docx_file):
    doc = docx.Document(io.BytesIO(docx_file.read()))
    text = ""
    for para in doc.paragraphs:
        text += para.text + "\n"
    return text

def extract_paper_content(paper_file):
    if paper_file is not None:
        if paper_file.type == "application/pdf":
            return extract_text_from_pdf(paper_file)
        elif paper_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            return extract_text_from_docx(paper_file)
    return ""

def extract_title_and_keywords(text):
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    title = lines[0] if lines else "æœªçŸ¥æ ‡é¢˜"
    keyword_pattern = r"(?:Keywords|å…³é”®è¯)[:ï¼š]?\s*(.*)"
    match = re.search(keyword_pattern, text, re.IGNORECASE)
    keywords = match.group(1) if match else "æ— å…³é”®è¯"
    return title, keywords

def analyze_paper_subject(paper_file):
    text = extract_paper_content(paper_file)
    title, keywords = extract_title_and_keywords(text)
    title_en = translate_text(title)
    keywords_en = translate_text(keywords)

    subjects = {
        "ç”µåŠ›ç³»ç»Ÿ": 40,
        "æ§åˆ¶ç†è®º": 35,
        "è®¡ç®—æœºç§‘å­¦": 25
    }

    st.markdown("### ğŸ“˜ è®ºæ–‡æ ‡é¢˜åŠå…³é”®è¯ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰")
    st.markdown(f"**æ ‡é¢˜ï¼ˆä¸­æ–‡ï¼‰**ï¼š{title}")
    st.markdown(f"**Title (English)**ï¼š{title_en}")
    st.markdown(f"**å…³é”®è¯ï¼ˆä¸­æ–‡ï¼‰**ï¼š{keywords}")
    st.markdown(f"**Keywords (English)**ï¼š{keywords_en}")

    st.markdown("### ğŸ“Š è®ºæ–‡å­¦ç§‘æ–¹å‘åˆ†æ")
    for subject, percent in subjects.items():
        st.write(f"{subject}: {percent}%")

    return subjects

def perform_matching(conference_file, paper_file):
    if conference_file is not None:
        try:
            conference_data = pd.read_excel(conference_file)
            st.success("âœ… ä¼šè®®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            paper_subjects = analyze_paper_subject(paper_file)
            matching_conferences = []

            for index, row in conference_data.iterrows():
                if 'Symposium' not in row['ä¼šè®®å']:
                    conference_subjects = row['ä¼šè®®ä¸»é¢˜æ–¹å‘'].split(',')
                    matching_score = 0
                    for subject in paper_subjects:
                        if subject in conference_subjects:
                            matching_score += paper_subjects[subject]

                    if matching_score > 0:
                        matching_conferences.append({
                            "ä¼šè®®ç³»åˆ—åä¸ä¼šè®®å": f"{row['ä¼šè®®ç³»åˆ—å']} - {row['ä¼šè®®å']}",
                            "å®˜ç½‘é“¾æ¥": row['å®˜ç½‘é“¾æ¥'],
                            "åŠ¨æ€å‡ºç‰ˆæ ‡è®°": row['åŠ¨æ€å‡ºç‰ˆæ ‡è®°'],
                            "æˆªç¨¿æ—¶é—´": row['æˆªç¨¿æ—¶é—´'],
                            "å‰©ä½™å¤©æ•°": calculate_days_left(row['æˆªç¨¿æ—¶é—´']),
                            "è®ºæ–‡ç ”ç©¶æ–¹å‘åŒ¹é…": f"ä¸{row['ä¼šè®®ä¸»é¢˜æ–¹å‘']}åŒ¹é…"
                        })

            if matching_conferences:
                st.markdown("### âœ… æ¨èåŒ¹é…ä¼šè®®")
                for conf in matching_conferences:
                    st.markdown(f"**ä¼šè®®æ¨èï¼š{conf['ä¼šè®®ç³»åˆ—åä¸ä¼šè®®å']}**")
                    st.markdown(f"å®˜ç½‘é“¾æ¥: [{conf['å®˜ç½‘é“¾æ¥']}]({conf['å®˜ç½‘é“¾æ¥']})")
                    st.write(f"åŠ¨æ€å‡ºç‰ˆæ ‡è®°: {conf['åŠ¨æ€å‡ºç‰ˆæ ‡è®°']}")
                    st.write(f"æˆªç¨¿æ—¶é—´: {conf['æˆªç¨¿æ—¶é—´']} ï¼ˆå‰©ä½™ {conf['å‰©ä½™å¤©æ•°']} å¤©ï¼‰")
                    st.write(f"åŒ¹é…åˆ†æ: {conf['è®ºæ–‡ç ”ç©¶æ–¹å‘åŒ¹é…']}")
            else:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„ä¼šè®®")
        except Exception as e:
            st.error(f"åŠ è½½ä¼šè®®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    else:
        st.warning("è¯·ä¸Šä¼ ä¼šè®®æ–‡ä»¶")

def main():
    st.title("ğŸ“„ è®ºæ–‡ä¸ä¼šè®®åŒ¹é…ç³»ç»Ÿ")
    conference_file = upload_conference_file()
    paper_file = upload_paper_file()

    if paper_file:
        st.info("æ­£åœ¨è¿›è¡Œè®ºæ–‡åˆ†æ...")
        time.sleep(1)
        perform_matching(conference_file, paper_file)
    else:
        st.warning("è¯·ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ä»¥è¿›è¡Œåˆ†æå’ŒåŒ¹é…")

if __name__ == "__main__":
    main()
