import streamlit as st
import pandas as pd
import pdfplumber
import docx
from datetime import datetime
from sentence_transformers import SentenceTransformer, util
import os

st.set_page_config(page_title="è®ºæ–‡åŒ¹é…æ¨èç³»ç»Ÿ", layout="wide")
st.title("ğŸ“„ è®ºæ–‡æ™ºèƒ½åŒ¹é…æ¨èä¼šè®®")

model = SentenceTransformer("all-MiniLM-L6-v2")

# æ–‡ä»¶çŠ¶æ€åˆå§‹åŒ–
if "paper_file" not in st.session_state:
    st.session_state.paper_file = None
if "conference_file" not in st.session_state:
    st.session_state.conference_file = None


# -------------------- æ–‡ä»¶ä¸Šä¼ åŒºå— --------------------

st.header("1ï¸âƒ£ ä¸Šä¼ ä¼šè®®æ–‡ä»¶ï¼ˆExcelï¼‰")
conf_col1, conf_col2 = st.columns([4, 1])

with conf_col1:
    uploaded_conf = st.file_uploader(
        "ä¸Šä¼ åŒ…å«ä¼šè®®ä¿¡æ¯çš„ Excel æ–‡ä»¶ï¼ˆä¼šè®®åç§°ã€æ–¹å‘ã€ä¸»é¢˜ã€ç»†åˆ†å…³é”®è¯ã€å®˜ç½‘é“¾æ¥ã€æˆªç¨¿æ—¶é—´...ï¼‰",
        type=["xlsx"],
        key="conference_uploader"
    )
    if uploaded_conf:
        st.session_state.conference_file = uploaded_conf

with conf_col2:
    if st.button("ğŸ—‘ æ¸…é™¤ä¼šè®®æ–‡ä»¶"):
        st.session_state.conference_file = None


st.divider()

st.header("2ï¸âƒ£ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ï¼ˆPDF / Wordï¼‰")
paper_col1, paper_col2 = st.columns([4, 1])

with paper_col1:
    uploaded_paper = st.file_uploader(
        "ä¸Šä¼ éœ€è¦åŒ¹é…çš„è®ºæ–‡æ–‡ä»¶",
        type=["pdf", "docx"],
        key="paper_uploader"
    )
    if uploaded_paper:
        st.session_state.paper_file = uploaded_paper

with paper_col2:
    if st.button("ğŸ—‘ æ¸…é™¤è®ºæ–‡æ–‡ä»¶"):
        st.session_state.paper_file = None

st.divider()

# -------------------- å·¥å…·å‡½æ•° --------------------

def extract_text(file):
    if file.name.endswith(".pdf"):
        with pdfplumber.open(file) as pdf:
            text = "\n".join(page.extract_text() or "" for page in pdf.pages)
    elif file.name.endswith(".docx"):
        doc = docx.Document(file)
        text = "\n".join(paragraph.text for paragraph in doc.paragraphs)
    else:
        return ""
    return text


def extract_sections(text):
    # ç®€å•åˆ†æ®µæŠ½å– title, abstract, keywords, conclusionï¼ˆå¯ä¼˜åŒ–ï¼‰
    sections = {
        "title": text.split("\n")[0],
        "abstract": "",
        "keywords": "",
        "conclusion": "",
    }
    lowered = text.lower()
    if "abstract" in lowered:
        sections["abstract"] = text[lowered.find("abstract"):lowered.find("introduction") if "introduction" in lowered else 1000]
    if "keywords" in lowered:
        start = lowered.find("keywords")
        end = lowered.find("\n", start + 8)
        sections["keywords"] = text[start:end].replace("Keywords", "").replace(":", "").strip()
    if "conclusion" in lowered:
        start = lowered.find("conclusion")
        sections["conclusion"] = text[start:start + 800]
    return sections


def compute_similarity(text1, text2):
    emb1 = model.encode(text1, convert_to_tensor=True)
    emb2 = model.encode(text2, convert_to_tensor=True)
    return float(util.cos_sim(emb1, emb2)[0])


# -------------------- åŒ¹é…é€»è¾‘ --------------------

def match_and_display(paper_text, conference_df):
    sections = extract_sections(paper_text)
    combined_text = " ".join([sections[k] for k in ["title", "abstract", "keywords", "conclusion"] if sections[k]])

    best_matches = []

    for _, row in conference_df.iterrows():
        conf_name = row["ä¼šè®®åç§°"]
        direction = str(row.get("ä¼šè®®æ–¹å‘", ""))
        topic = str(row.get("ä¼šè®®ä¸»é¢˜æ–¹å‘", ""))
        sub_keywords = str(row.get("ç»†åˆ†å…³é”®è¯", ""))
        deadline = str(row.get("æˆªç¨¿æ—¶é—´", ""))
        link = row.get("å®˜ç½‘é“¾æ¥", "")

        full_conf_info = " ".join([direction, topic, sub_keywords])
        similarity = compute_similarity(combined_text, full_conf_info)

        # åŒ¹é…å…³é”®è¯è®°å½•
        matched_terms = []
        for word in sub_keywords.split(","):
            word = word.strip().lower()
            if word and word in combined_text.lower():
                matched_terms.append(word)

        try:
            deadline_date = pd.to_datetime(deadline)
            days_left = (deadline_date - datetime.now()).days
        except:
            days_left = "æœªçŸ¥"

        best_matches.append({
            "ä¼šè®®åç§°": conf_name,
            "åŒ¹é…åˆ†æ•°": round(similarity, 3),
            "åŒ¹é…å…³é”®è¯": ", ".join(matched_terms) if matched_terms else "æ— æ˜æ˜¾å…³é”®è¯åŒ¹é…",
            "å®˜ç½‘é“¾æ¥": link,
            "è·ç¦»æˆªç¨¿æ—¶é—´": f"{days_left} å¤©" if isinstance(days_left, int) else "æ— æ³•è§£æ"
        })

    sorted_matches = sorted(best_matches, key=lambda x: x["åŒ¹é…åˆ†æ•°"], reverse=True)[:2]

    st.subheader("ğŸ“Œ æ¨èä¼šè®®")
    for match in sorted_matches:
        st.markdown(f"""
        **ä¼šè®®åç§°ï¼š** {match['ä¼šè®®åç§°']}  
        **åŒ¹é…åˆ†æ•°ï¼š** {match['åŒ¹é…åˆ†æ•°']}  
        **å…³é”®è¯åŒ¹é…ï¼š** {match['åŒ¹é…å…³é”®è¯']}  
        **å®˜ç½‘é“¾æ¥ï¼š** [{match['å®˜ç½‘é“¾æ¥']}]({match['å®˜ç½‘é“¾æ¥']})  
        **è·ç¦»æˆªç¨¿æ—¶é—´ï¼š** {match['è·ç¦»æˆªç¨¿æ—¶é—´']}  
        ---
        """)


# -------------------- ä¸»æ‰§è¡Œé€»è¾‘ --------------------

if st.session_state.paper_file and st.session_state.conference_file:
    try:
        conf_df = pd.read_excel(st.session_state.conference_file)
        paper_text = extract_text(st.session_state.paper_file)
        if not paper_text.strip():
            st.error("è®ºæ–‡å†…å®¹ä¸ºç©ºï¼Œå¯èƒ½æå–å¤±è´¥")
        else:
            match_and_display(paper_text, conf_df)
    except Exception as e:
        st.error(f"å¤„ç†æ—¶å‡ºé”™ï¼š{e}")
