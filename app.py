import streamlit as st
import pandas as pd
import re
import jieba
import jieba.analyse
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from googletrans import Translator

st.set_page_config(page_title="ä¼šè®®åŒ¹é…åŠ©æ‰‹", layout="wide")

if 'conference_df' not in st.session_state:
    st.session_state.conference_df = None

translator = Translator()

def extract_title_abstract_keywords(text):
    lines = text.splitlines()
    title, abstract, keywords = "", "", ""
    title_found, abstract_found, keywords_found = False, False, False

    for i, line in enumerate(lines):
        clean_line = line.strip()
        if not title_found and 5 < len(clean_line) < 200:
            title = clean_line
            title_found = True
            continue

        if not abstract_found and re.search(r'æ‘˜è¦|Abstract', clean_line, re.IGNORECASE):
            abstract_lines = []
            for j in range(i+1, len(lines)):
                l = lines[j].strip()
                if re.search(r'å…³é”®è¯|å…³é”®å­—|Keywords|Index Terms', l, re.IGNORECASE):
                    break
                abstract_lines.append(l)
            abstract = " ".join(abstract_lines).strip()
            abstract_found = True
            continue

        if not keywords_found and re.search(r'å…³é”®è¯|å…³é”®å­—|Keywords|Index Terms', clean_line, re.IGNORECASE):
            keywords = re.sub(r'(å…³é”®è¯|å…³é”®å­—|Keywords|Index Terms)[:ï¼š]?', '', clean_line, flags=re.IGNORECASE).strip()
            keywords_found = True
            continue

    return title, abstract, keywords

def translate_text(text, src='auto', dest='en'):
    try:
        return translator.translate(text, src=src, dest=dest).text
    except Exception:
        return text

def analyze_subject_direction(text, top_k=5):
    return jieba.analyse.extract_tags(text, topK=top_k, withWeight=True)

def match_conference(paper_text, conference_df):
    tfidf = TfidfVectorizer()
    corpus = [paper_text] + conference_df["ç®€ä»‹"].fillna("").tolist()
    tfidf_matrix = tfidf.fit_transform(corpus)
    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()
    conference_df["åŒ¹é…åˆ†æ•°"] = cosine_sim
    return conference_df.sort_values(by="åŒ¹é…åˆ†æ•°", ascending=False).head(5)

# é¡µé¢å¸ƒå±€
st.title("ğŸ“Œ è®ºæ–‡æ™ºèƒ½åŒ¹é…ä¼šè®®æ¨èå·¥å…·")

col1, col2 = st.columns([1, 2])

with col1:
    st.header("ğŸ“… ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
    conf_file = st.file_uploader("ä¸Šä¼ ä¼šè®®Excelæ–‡ä»¶", type=["xls", "xlsx"], key="conf")
    if conf_file:
        st.session_state.conference_df = pd.read_excel(conf_file)
        st.success("âœ… ä¼šè®®æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")

with col2:
    st.header("ğŸ“„ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
    paper_file = st.file_uploader("ä¸Šä¼ è®ºæ–‡ï¼ˆTXTæ ¼å¼ï¼‰", type=["txt"], key="paper")
    if paper_file:
        paper_text = paper_file.read().decode("utf-8")
        title, abstract, keywords = extract_title_abstract_keywords(paper_text)

        if not (title or abstract):
            st.error("âŒ æ— æ³•è¯†åˆ«æ ‡é¢˜æˆ–æ‘˜è¦ï¼Œè¯·æ£€æŸ¥è®ºæ–‡æ ¼å¼ã€‚")
        else:
            st.subheader("ğŸ“‹ æå–å†…å®¹ç»“æ„")
            st.markdown(f"**æ ‡é¢˜è¯†åˆ«ï¼š** {title}")
            st.markdown(f"**æ‘˜è¦è¯†åˆ«ï¼š** {abstract}")
            st.markdown(f"**å…³é”®è¯è¯†åˆ«ï¼š** {keywords}")

            # ç¿»è¯‘
            title_en = translate_text(title)
            abstract_en = translate_text(abstract)
            keywords_en = translate_text(keywords)

            st.subheader("ğŸŒ ä¸­è‹±æ–‡å¯¹ç…§")
            st.markdown(f"- **æ ‡é¢˜**: {title}  \n  **Title**: {title_en}")
            st.markdown(f"- **æ‘˜è¦**: {abstract}  \n  **Abstract**: {abstract_en}")
            st.markdown(f"- **å…³é”®è¯**: {keywords}  \n  **Keywords**: {keywords_en}")

            st.subheader("ğŸ“Š å­¦ç§‘æ–¹å‘å…³é”®è¯åˆ†æ")
            combined_text = f"{title} {abstract} {keywords}"
            directions = analyze_subject_direction(combined_text)
            for word, score in directions:
                st.write(f"- `{word}`ï¼ˆæƒé‡: {round(score, 3)}ï¼‰")

            if st.session_state.conference_df is not None:
                st.subheader("ğŸ“ æ¨èåŒ¹é…çš„ä¼šè®®")
                result_df = match_conference(combined_text, st.session_state.conference_df.copy())
                for idx, row in result_df.iterrows():
                    st.markdown(f"### ğŸ”¹ {row['ä¼šè®®å']}")
                    st.markdown(f"- åŒ¹é…åˆ†æ•°ï¼š{round(row['åŒ¹é…åˆ†æ•°'], 4)}")
                    st.markdown(f"- å®˜ç½‘é“¾æ¥ï¼š[{row['å®˜ç½‘é“¾æ¥']}]({row['å®˜ç½‘é“¾æ¥']})")
                    st.markdown("---")
            else:
                st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ ä¼šè®®Excelæ–‡ä»¶")
