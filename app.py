import streamlit as st
import pandas as pd
import datetime
import io
import time
import re
from docx import Document
import fitz  # PyMuPDFï¼Œç”¨äºPDFè§£æ
import requests

# ä½¿ç”¨ç¬¬ä¸‰æ–¹APIç¿»è¯‘ï¼ˆæ— éœ€å®‰è£…åº“ï¼‰
def translate_text(text, target_lang="zh"):
    try:
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            "client": "gtx",
            "sl": "en",
            "tl": target_lang,
            "dt": "t",
            "q": text
        }
        response = requests.get(url, params=params)
        result = response.json()
        return "".join([item[0] for item in result[0]])
    except:
        return "(ç¿»è¯‘å¤±è´¥)"

# æå– PDF æ–‡æœ¬
def extract_text_from_pdf(file):
    try:
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text("text")
        return text
    except Exception as e:
        st.error(f"PDFè§£æå¤±è´¥: {e}")
        return ""

# æå– Word æ–‡æœ¬
def extract_text_from_word(file):
    try:
        document = Document(file)
        text = "\n".join([para.text for para in document.paragraphs])
        return text
    except Exception as e:
        st.error(f"Wordè§£æå¤±è´¥: {e}")
        return ""

# æå–è®ºæ–‡é¢˜ç›®
def extract_title(text):
    lines = text.split('\n')
    for line in lines:
        if 5 < len(line) < 200 and line.strip().istitle():
            return line.strip()
    return lines[0].strip() if lines else "æ— æ³•è¯†åˆ«é¢˜ç›®"

# æå–å…³é”®è¯
def extract_keywords(text):
    patterns = [r"(?i)(Keywords|Index Terms)[:ï¼š]?\s*(.*)"]
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(2)
    return "æ— æ³•è¯†åˆ«å…³é”®è¯"

# æ¨¡æ‹Ÿå­¦ç§‘åˆ†æï¼ˆä½ å¯ä»¥æ¢æˆæ¨¡å‹ï¼‰
def analyze_paper_subject(text):
    subjects = {
        "ç”µåŠ›ç³»ç»Ÿ": 40,
        "æ§åˆ¶ç†è®º": 35,
        "è®¡ç®—æœºç§‘å­¦": 25
    }
    return subjects

# è®¡ç®—å‰©ä½™å¤©æ•°
def calculate_days_left(cutoff_date):
    return (cutoff_date - datetime.datetime.now().date()).days

# ä¸»å‡½æ•°
def main():
    st.set_page_config(layout="wide")
    st.title("è®ºæ–‡ä¸ä¼šè®®åŒ¹é…ç³»ç»Ÿ")
    col1, col2 = st.columns(2)
    with col1:
        st.header("ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
        conference_file = st.file_uploader("ä¸Šä¼ ä¼šè®® Excel æ–‡ä»¶", type=["xlsx"], key="conf")
    with col2:
        st.header("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
        paper_file = st.file_uploader("ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ (PDF æˆ– Word)", type=["pdf", "docx"], key="paper")
    
    # å¦‚æœä¸Šä¼ äº†è®ºæ–‡æ–‡ä»¶ï¼Œç«‹å³åˆ†æ
    if paper_file:
        st.markdown("## ğŸ“„ è®ºæ–‡å†…å®¹è§£æç»“æœ")
        file_text = ""
        if paper_file.name.endswith(".pdf"):
            file_text = extract_text_from_pdf(paper_file)
        elif paper_file.name.endswith(".docx"):
            file_text = extract_text_from_word(paper_file)
        if not file_text.strip():
            st.error("æœªèƒ½æˆåŠŸæå–è®ºæ–‡å†…å®¹")
            return
        
        # æå–é¢˜ç›®ä¸å…³é”®è¯
        title = extract_title(file_text)
        keywords = extract_keywords(file_text)
        
        # ç¿»è¯‘ç»“æœ
        title_zh = translate_text(title)
        keywords_zh = translate_text(keywords)
        
        st.subheader("è®ºæ–‡é¢˜ç›®")
        st.write(title_zh)
        
        st.subheader("å…³é”®è¯")
        st.write(keywords_zh)

if __name__ == "__main__":
    main()
