
import streamlit as st
import pandas as pd
import datetime
import os
import fitz  # PyMuPDFï¼Œç”¨äºPDFè§£æ
import docx
from io import BytesIO

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="è®ºæ–‡ä¼šè®®åŒ¹é…ç³»ç»Ÿ", layout="wide")

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“„ è®ºæ–‡ä¼šè®®åŒ¹é…ä¸å­¦ç§‘æ–¹å‘åˆ†æç³»ç»Ÿ")

# ä¸Šä¼ åŒºåŸŸå¸ƒå±€
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("ğŸ“ ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
    conf_file = st.file_uploader("ä¸Šä¼  Excel ä¼šè®®æ–‡ä»¶", type=["xlsx"], key="conf")

with col2:
    st.subheader("ğŸ“„ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶")
    paper_file = st.file_uploader("ä¸Šä¼  PDF æˆ– Word æ–‡ä»¶", type=["pdf", "docx"], key="paper")

# æ˜¾ç¤ºåˆ†å‰²çº¿
st.markdown("---")


def extract_paper_content(file):
    if file.name.endswith(".pdf"):
        doc = fitz.open(stream=file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        title = text.split("\n")[0].strip() if text else "æœªçŸ¥æ ‡é¢˜"
        abstract = text[:1500].strip()
        keywords = "æš‚æœªæå–"
        return title, abstract, keywords
    elif file.name.endswith(".docx"):
        document = docx.Document(file)
        full_text = "\n".join([para.text for para in document.paragraphs])
        title = full_text.split("\n")[0].strip() if full_text else "æœªçŸ¥æ ‡é¢˜"
        abstract = full_text[:1500].strip()
        keywords = "æš‚æœªæå–"
        return title, abstract, keywords
    else:
        return "æœªçŸ¥æ ‡é¢˜", "", ""

def analyze_paper_subject(title, abstract, keywords):
    # ç®€å•å…³é”®è¯è¯†åˆ«é€»è¾‘ï¼Œå¯æ›¿æ¢ä¸ºMLæ¨¡å‹
    combined = " ".join([title, abstract, keywords]).lower()
    subjects = {
        "äººå·¥æ™ºèƒ½": ["reinforcement learning", "neural network", "deep learning"],
        "ç”µåŠ›ç”µå­": ["PWM", "converter", "voltage source", "rectifier"],
        "æ§åˆ¶å·¥ç¨‹": ["PI control", "controller", "feedback"],
        "é€šä¿¡æŠ€æœ¯": ["5G", "antenna", "signal"],
        "ç”Ÿç‰©åŒ»å­¦": ["gene", "clinical", "medical"]
    }
    matched = {}
    for subject, keywords in subjects.items():
        score = sum(1 for kw in keywords if kw in combined)
        if score > 0:
            matched[subject] = score

    if not matched:
        return "ğŸ“˜ æœªèƒ½è¯†åˆ«æ˜ç¡®çš„å­¦ç§‘æ–¹å‘", "æœªèƒ½åŒ¹é…ä»»ä½•å­¦ç§‘å…³é”®è¯ã€‚", ""

    sorted_subjects = sorted(matched.items(), key=lambda x: x[1], reverse=True)
    result = "ï¼Œ".join([f"{k}ï¼ˆ{v}ï¼‰" for k, v in sorted_subjects])
    explanation = "\n".join([f"- **{k}**ï¼šåŒ¹é…äº† {v} ä¸ªå…³é”®è¯ã€‚" for k, v in sorted_subjects])
    return "ğŸ“˜ è¯†åˆ«å‡ºçš„å­¦ç§‘æ–¹å‘ï¼š", result, explanation


def match_paper_to_conference(title, abstract, keywords, conf_df):
    paper_text = " ".join([title, abstract, keywords]).lower()
    results = []
    for idx, row in conf_df.iterrows():
        conf_name = str(row.get("ä¼šè®®å", ""))
        conf_series = str(row.get("ä¼šè®®ç³»åˆ—å", ""))
        topics = str(row.get("ä¼šè®®ä¸»é¢˜æ–¹å‘", "")).lower()
        website = row.get("å®˜ç½‘é“¾æ¥", "")
        deadline = row.get("æˆªç¨¿æ—¶é—´", "")
        is_symp = "symposium" in conf_name.lower()

        if not is_symp:
            continue  # ä¸»ä¼šä¸å¾æ”¶è®ºæ–‡ï¼Œè·³è¿‡

        match_score = sum(kw in topics or kw in conf_name.lower() for kw in title.lower().split())

        if match_score > 0:
            results.append({
                "ä¼šè®®å…¨å": conf_series + " - " + conf_name,
                "åŒ¹é…å¾—åˆ†": match_score,
                "ä¼šè®®ä¸»é¢˜æ–¹å‘": topics,
                "æˆªç¨¿æ—¶é—´": deadline,
                "å®˜ç½‘é“¾æ¥": website
            })

    if not results:
        return None

    df = pd.DataFrame(results).sort_values(by="åŒ¹é…å¾—åˆ†", ascending=False)
    return df.head(5)


# å¦‚æœè®ºæ–‡ä¸Šä¼ äº†å°±åˆ†æ
if paper_file is not None:
    with st.spinner("æ­£åœ¨åˆ†æè®ºæ–‡å†…å®¹..."):
        title, abstract, keywords = extract_paper_content(paper_file)
        heading, result, explanation = analyze_paper_subject(title, abstract, keywords)

    st.markdown("### ğŸ§  è®ºæ–‡å­¦ç§‘æ–¹å‘åˆ†æ")
    st.markdown(f"**è®ºæ–‡æ ‡é¢˜ï¼š** {title}")
    st.markdown(f"**è¯†åˆ«å…³é”®è¯ï¼š** {keywords}")
    st.markdown(f"**{heading}**")
    st.markdown(f"{result}")
    st.markdown(explanation)

# å¦‚æœä¸¤ä¸ªæ–‡ä»¶éƒ½æœ‰ï¼Œæ‰§è¡ŒåŒ¹é…
if paper_file and conf_file:
    conf_df = pd.read_excel(conf_file)
    st.markdown("---")
    st.subheader("ğŸ“Œ åŒ¹é…æ¨èçš„ä¼šè®®ï¼ˆæ ¹æ®è®ºæ–‡å†…å®¹ï¼‰")

    match_df = match_paper_to_conference(title, abstract, keywords, conf_df)

    if match_df is not None:
        for i, row in match_df.iterrows():
            st.markdown(f"#### ğŸ”¹ {row['ä¼šè®®å…¨å']}")
            st.markdown(f"- **ä¸»é¢˜æ–¹å‘ï¼š** {row['ä¼šè®®ä¸»é¢˜æ–¹å‘']}")
            st.markdown(f"- **æˆªç¨¿æ—¶é—´ï¼š** {row['æˆªç¨¿æ—¶é—´']}")
            st.markdown(f"- **ä¼šè®®é“¾æ¥ï¼š** [{row['å®˜ç½‘é“¾æ¥']}]({row['å®˜ç½‘é“¾æ¥']})")
            st.markdown("---")
    else:
        st.markdown("âš ï¸ æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„ä¼šè®®ï¼Œå»ºè®®æŸ¥çœ‹å¤§æ–¹å‘ç›¸è¿‘çš„ä¼šè®®ã€‚")

st.markdown("ğŸ“Œ å¦‚éœ€å¤åˆ¶ä¼šè®®ä¿¡æ¯ï¼Œå¯å³é”®é“¾æ¥æˆ–ç›´æ¥ç‚¹å‡»è®¿é—®ã€‚")
