import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from PyPDF2 import PdfReader
import tempfile
import os
from datetime import datetime

st.set_page_config(layout="wide")
st.title("ğŸ“„ è®ºæ–‡åŒ¹é…ä¼šè®®åŠ©æ‰‹")

# åˆå§‹åŒ–æ¨¡å‹
model = SentenceTransformer('all-MiniLM-L6-v2')

# åˆå§‹åŒ– session_state
for key in ["conference_file", "paper_file"]:
    if key not in st.session_state:
        st.session_state[key] = None

# å·¦å³å¸ƒå±€
col1, col2 = st.columns(2)

# ä¸Šä¼ ä¼šè®®æ–‡ä»¶
with col1:
    st.subheader("ğŸ“… ä¸Šä¼ ä¼šè®®æ–‡ä»¶")
    conference_uploaded = st.file_uploader("é€‰æ‹©åŒ…å«ä¼šè®®ä¿¡æ¯çš„Excelæ–‡ä»¶", type=["xlsx"], key="conf_uploader")
    if st.button("âŒ æ¸…é™¤ä¼šè®®æ–‡ä»¶"):
        st.session_state.conference_file = None
        conference_uploaded = None

    if conference_uploaded:
        try:
            df = pd.read_excel(conference_uploaded)
            df.columns = df.columns.str.strip()

            # å­—æ®µåæ ‡å‡†åŒ–
            rename_map = {}
            if "ä¼šè®®åç§°" in df.columns:
                rename_map["ä¼šè®®åç§°"] = "ä¼šè®®å"
            df.rename(columns=rename_map, inplace=True)

            required_columns = ["ä¼šè®®å", "ä¼šè®®æ–¹å‘", "ä¼šè®®ä¸»é¢˜æ–¹å‘", "ç»†åˆ†å…³é”®è¯", "ä¼šè®®ç³»åˆ—å", "å®˜ç½‘é“¾æ¥", "åŠ¨æ€å‡ºç‰ˆæ ‡è®°", "æˆªç¨¿æ—¶é—´"]
            missing = [col for col in required_columns if col not in df.columns]
            if missing:
                st.error(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µï¼š{ ' / '.join(missing) }")
            else:
                st.session_state.conference_file = df
                st.success("âœ… ä¼šè®®æ–‡ä»¶ä¸Šä¼ å¹¶è¯»å–æˆåŠŸ")
        except Exception as e:
            st.error(f"âŒ ä¼šè®®æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")

# ä¸Šä¼ è®ºæ–‡æ–‡ä»¶
with col2:
    st.subheader("ğŸ“ ä¸Šä¼ è®ºæ–‡æ–‡ä»¶ï¼ˆPDFï¼‰")
    paper_uploaded = st.file_uploader("ä¸Šä¼ è®ºæ–‡ PDF æ–‡ä»¶", type=["pdf"], key="paper_uploader")
    if st.button("âŒ æ¸…é™¤è®ºæ–‡æ–‡ä»¶"):
        st.session_state.paper_file = None
        paper_uploaded = None

    if paper_uploaded:
        try:
            # ä¸´æ—¶ä¿å­˜ PDF
            temp_dir = tempfile.mkdtemp()
            temp_path = os.path.join(temp_dir, paper_uploaded.name)
            with open(temp_path, "wb") as f:
                f.write(paper_uploaded.read())

            # è¯»å– PDF æ–‡æœ¬
            reader = PdfReader(temp_path)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + " "
            st.session_state.paper_file = text.strip()
            st.success("âœ… è®ºæ–‡å†…å®¹æå–æˆåŠŸ")
        except Exception as e:
            st.error(f"âŒ PDF å¤„ç†å¤±è´¥ï¼š{e}")

# æ‰§è¡ŒåŒ¹é…
if st.session_state.conference_file is not None and st.session_state.paper_file is not None:
    st.divider()
    st.subheader("ğŸ“Š åŒ­é…ç»“æœ")

    paper_embedding = model.encode(st.session_state.paper_file, convert_to_tensor=True)
    results = []

    # å¤„ç†ä¼šè®®æ•°æ®
    for _, row in st.session_state.conference_file.iterrows():
        row_text = " ".join(str(row[col]) for col in ["ä¼šè®®æ–¹å‘", "ä¼šè®®ä¸»é¢˜æ–¹å‘", "ç»†åˆ†å…³é”®è¯"] if pd.notna(row[col]))
        row_embedding = model.encode(row_text, convert_to_tensor=True)
        similarity = util.cos_sim(paper_embedding, row_embedding).item()
        
        # è®¡ç®—æˆªç¨¿æ—¶é—´
        if pd.notna(row.get("æˆªç¨¿æ—¶é—´", None)):
            try:
                deadline = datetime.strptime(str(row["æˆªç¨¿æ—¶é—´"]), "%Y-%m-%d")
                days_left = (deadline - datetime.now()).days
            except Exception as e:
                days_left = "æœªçŸ¥"
        else:
            days_left = "æœªçŸ¥"
        
        # æå–æ¨èä¿¡æ¯
        results.append({
            "ä¼šè®®æ¨èæ ‡é¢˜": f"{row['ä¼šè®®ç³»åˆ—å']} - {row['ä¼šè®®å']}",
            "å®˜ç½‘é“¾æ¥": row["å®˜ç½‘é“¾æ¥"],
            "åŠ¨æ€å‡ºç‰ˆæ ‡è®°": row["åŠ¨æ€å‡ºç‰ˆæ ‡è®°"],
            "è·ç¦»æˆªç¨¿æ—¶é—´(å¤©)": days_left,
            "åŒ¹é…åˆ†æ•°": round(similarity, 4),
            "ä¼šè®®æ–¹å‘": row["ä¼šè®®æ–¹å‘"],
            "è®ºæ–‡ç ”ç©¶æ–¹å‘": "è®ºæ–‡ç ”ç©¶æ–¹å‘å¾…æå–",  # è¿™é‡Œæš‚æ—¶è®¾ç½®ä¸ºå¾…æå–ï¼Œåç»­å¯ä»¥åŠ å…¥ä»è®ºæ–‡ä¸­æå–ä¸»è¦ç ”ç©¶æ–¹å‘çš„ä»£ç 
            "ç»†åˆ†å…³é”®è¯": row["ç»†åˆ†å…³é”®è¯"],
            "åŒ¹é…åˆ†æ": f"è¯¥ä¼šè®®çš„ã€{row['ä¼šè®®æ–¹å‘']}ã€‘ä¸è®ºæ–‡çš„ç ”ç©¶æ–¹å‘åŒ¹é…åº¦è¾ƒé«˜ã€‚"  # å¯æ ¹æ®å®é™…éœ€è¦è°ƒæ•´åŒ¹é…æè¿°
        })

    # æ’åºå¹¶ç­›é€‰å‰3ä¸ªæ¨èä¼šè®®
    sorted_results = sorted(results, key=lambda x: x["åŒ¹é…åˆ†æ•°"], reverse=True)
    top_results = sorted_results[:3]

    # æ˜¾ç¤ºç»“æœ
    for result in top_results:
        st.markdown(f"### {result['ä¼šè®®æ¨èæ ‡é¢˜']}")
        st.markdown(f"**å®˜ç½‘é“¾æ¥**: [ç‚¹å‡»è®¿é—®]({result['å®˜ç½‘é“¾æ¥']})")
        st.markdown(f"**åŠ¨æ€å‡ºç‰ˆæ ‡è®°**: {result['åŠ¨æ€å‡ºç‰ˆæ ‡è®°']}")
        st.markdown(f"**è·ç¦»æˆªç¨¿æ—¶é—´**: {result['è·ç¦»æˆªç¨¿æ—¶é—´(å¤©)']} å¤©")
        st.markdown(f"**åŒ¹é…åˆ†æ•°**: {result['åŒ¹é…åˆ†æ•°']}")
        st.markdown(f"**è®ºæ–‡ç ”ç©¶æ–¹å‘ä¸ä¼šè®®åŒ¹é…åˆ†æ**: {result['åŒ¹é…åˆ†æ']}")
        st.markdown(f"**ç»†åˆ†å…³é”®è¯**: {result['ç»†åˆ†å…³é”®è¯']}")
        st.markdown("---")
